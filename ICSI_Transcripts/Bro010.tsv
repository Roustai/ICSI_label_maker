"me018"::	O_K, we're on.::	0
"me013"::	O_K, what are we talking about today?::	0
"mn007"::	I don't know. Do you have news from the conference talk?::	0
"mn007"::	Uh, that was::	0
"me013"::	Uh -::	0
"fn002"::	Yesterday::	0
"mn007"::	programmed for yesterday -::	0
"mn007"::	I guess.::	0
"me013"::	Uh -::	0
"fn002"::	Yesterday morning on video conference.::	1
"me013"::	Uh,  oh,   I'm  sorry. I know -  now  I know what you're talking about. No, nobody's told me anything.::	0
"mn007"::	Well::	0
"me006"::	Oh. Conference call.::	0
"mn007"::	Alright.::	0
"me018"::	Oh, this was the, uh,::	0
"me018"::	talk where they were supposed to try to decide -::	0
"mn007"::	To -::	0
"mn007"::	to decide what to do, yeah.::	0
"fn002"::	Yeah.::	0
"me018"::	Ah, right.::	0
"me013"::	Yeah. No, that would have been a good thing to find out before this meeting, that's.  No, I have no - I have no idea. Um,::	0
"me013"::	Uh, so I mean, let's - let's assume for right now that we're just kind of plugging on ahead, because even if they::	0
"mn007"::	Yeah.::	0
"me013"::	tell us that, uh, the rules are different, uh, we're still interested in::	0
"me013"::	doing what we're doing. So what are you doing?::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Uh, well, we've -::	1
"mn007"::	a little bit worked on trying to see,::	0
"fn002"::	To improve -::	0
"mn007"::	uh, what were the bugs and the problem with the latencies. So,::	1
"mn007"::	We took - first we took the L_D_A filters and,::	0
"mn007"::	uh, we designed new filters,::	0
"mn007"::	using uh recursive filters actually.::	0
"me013"::	So when you say "we", is that something Sunil is doing or is that - ?::	0
"mn007"::	I'm sorry?::	0
"me013"::	Who is doing that?::	0
"mn007"::	Uh,  us.  Yeah.::	0
"me013"::	Oh, oh. Oh, O_K.::	0
"fn002"::	But -::	0
"mn007"::	So we took the filters -::	0
"mn007"::	the  FIR  filters::	0
"mn007"::	and we::	0
"mn007"::	designed, uh, I_I_R filters that have the same frequency response.::	0
"me013"::	Mm-hmm.::	0
"mn007"::	Well,::	1
"mn007"::	similar,  but that have shorter delays.::	1
"me013"::	Mm-hmm.::	0
"mn007"::	So they had two filters, one for the low frequency bands and another for the high frequency bands.::	0
"mn007"::	And so we redesigned two filters. And the low frequency band has::	1
"mn007"::	sixty-four milliseconds of delay, and the high frequency band filter has something like eleven milliseconds compared to the two hundred milliseconds of the::	1
"mn007"::	I_I_R filters.::	0
"mn007"::	But it's not yet test. So we have the filters but we still have to implement a routine that does recursive filtering and -::	0
"me013"::	O_K.::	0
"me013"::	You - you had a discussion with Sunil about this though?::	0
"mn007"::	No.::	0
"mn007"::	No.::	0
"me013"::	Uh- huh.::	0
"me013"::	Yeah, you should  talk  with him.::	0
"mn007"::	Yeah, yeah.::	0
"me013"::	Yeah.  No, I mean, because the - the - the - the whole problem that happened before was coordination, right? So - so you need to::	0
"mn007"::	Mm-hmm.::	0
"me013"::	discuss with him what we're doing, uh, cuz they could be doing the same thing and - or something.::	0
"mn007"::	Yeah.::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Uh, I - yeah, I don't know if th- that's what they were trying to -::	0
"me013"::	Right.::	0
"mn007"::	They were trying to do something different like::	0
"mn007"::	taking, uh - well, using filter that takes only a past and::	0
"mn007"::	this is just a little bit different. But I will- I will send him an email and tell him exactly what we are doing, so.::	0
"me013"::	Yeah, yeah. Um, I mean -::	0
"mn007"::	Um,::	0
"me013"::	We just - we just have to be in contact more. I think that - the - the fact that we -::	0
"mn007"::	Mm-hmm.::	0
"me013"::	we did that with - had that thing with the latencies was indicative of the fact that there wasn't enough communication. So.::	0
"mn007"::	Alright. Um,::	0
"me013"::	O_K.::	0
"mn007"::	Yeah.::	0
"mn007"::	Well, there is w- one, um,::	0
"mn007"::	remark about these filters, that::	0
"mn007"::	they don't have a linear phase. So,::	0
"me013"::	Right.::	0
"mn007"::	Well, I don't know, perhaps it - perhaps it doesn't hurt because the phase is almost linear but.::	0
"mn007"::	Um, and so, yeah, for the delay I gave you here, it's -::	0
"mn007"::	it's, uh, computed on::	0
"mn007"::	the five hertz modulation frequency, which is the -::	0
"mn007"::	mmm,::	0
"mn007"::	well,::	0
"mn007"::	the most important for speech  so .::	0
"mn007"::	Uh, this is the first thing.::	0
"fn002"::	The low f- f-::	0
"me013"::	So that would be, uh, a reduction of a hundred and thirty-six milliseconds, which, uh -::	0
"mn007"::	Yeah.::	0
"me013"::	What was the total we ended up with through the whole system?::	0
"mn007"::	Three hundred and thirty.::	0
"me013"::	So that would be within - ?::	0
"mn007"::	Yeah, but there are other points actually,::	0
"mn007"::	uh, which will perhaps add some more delay. Is that::	0
"mn007"::	some other - other stuff in the process were perhaps not very -::	0
"mn007"::	um::	0
"mn007"::	perf- well, not very correct,::	0
"mn007"::	like the downsampling which w- was simply dropping frames.::	0
"me013"::	Yeah.::	0
"mn007"::	Um,::	0
"mn007"::	so we will try also to add a nice downsampling having a filter::	0
"me013"::	Uh-huh.::	0
"mn007"::	that - that - well,::	0
"mn007"::	a low-pass filter at - at twenty-five hertz.::	0
"mn007"::	Uh, because wh- when - when we look at the L_D_A filters, well, they are basically low-pass but::	0
"mn007"::	they::	0
"mn007"::	leave a lot of what's above twenty-five hertz.::	0
"me013"::	Yeah.::	0
"mn007"::	Um, and so, yeah, this will be another filter which would add ten milliseconds again.::	0
"me013"::	Yeah.::	0
"mn007"::	Um,::	0
"mn007"::	yeah, and then there's a third thing,::	0
"mn007"::	is that,::	0
"mn007"::	um,::	0
"mn007"::	basically the way::	0
"mn007"::	on-line normalization was done::	0
"mn007"::	uh,::	0
"mn007"::	is just using this recursion::	0
"me013"::	Yeah.::	0
"mn007"::	on - on the um,::	0
"mn007"::	um,::	0
"mn007"::	on the feature stream,::	0
"mn007"::	and - but this is a filter, so it has also a delay.::	0
"mn007"::	Uh, and when we::	0
"mn007"::	look at this filter actually it has a delay of eighty-five milliseconds. So if we -::	0
"me013"::	Eighty - five .::	0
"mn007"::	Yeah.::	0
"mn007"::	If we want to be very::	0
"mn007"::	correct, so if we want to -::	0
"mn007"::	the estimation of the mean t- t- to - to be -::	0
"mn007"::	well,::	0
"mn007"::	the right estimation of the mean,::	0
"mn007"::	we have to t- to take eighty-five milliseconds in the future.::	0
"mn007"::	Mmm.::	0
"me013"::	Hmm!::	0
"me013"::	That's a little bit of a problem.::	0
"mn007"::	Yeah.::	0
"mn007"::	Um,::	0
"mn007"::	But, well, when we add up everything it's - it will be alright.::	1
"mn007"::	We would be at six- so, sixty-five,::	1
"mn007"::	plus ten, plus - for the downsampling, plus eighty-five for the on-line normalization.::	1
"mn007"::	So it's::	0
"me013"::	Uh, yeah, but then there's -::	0
"mn007"::	plus - plus eighty for the neural net and P_C_A.::	1
"me013"::	Oh.::	0
"mn007"::	So it would be around two hundred and forty - so, well,::	1
"me013"::	Just - just barely in there.::	1
"mn007"::	plus - plus the frames, but it's O_K.::	0
"me018"::	What's the allowable?::	1
"me013"::	Two-fifty, unless they changed the rules.::	1
"mn007"::	Hmm.::	0
"me013"::	Which there is - there's some discussion of. But -::	1
"mn007"::	Yeah.::	0
"me018"::	What were they thinking of changing it to?::	1
"me013"::	Uh, well the people who had very low latency want it to be low - uh, very -::	1
"me013"::	very- very narrow, uh, latency bound. And the people who have longer latency don't. So.::	1
"me018"::	Huh.::	0
"mn007"::	So, yeah.::	0
"me013"::	Unfortunately we're the main ones with long latency, but::	1
"me018"::	Ah!::	0
"me013"::	But, uh, you know, it's -::	0
"mn007"::	Yeah, and basically the best proposal had something like thirty or forty milliseconds of latency. So.::	1
"me013"::	Yeah.::	0
"mn007"::	Well.::	0
"me013"::	Yeah, so they were basically - I mean,::	0
"me013"::	they were more or less trading computation for performance and we were,::	0
"me013"::	uh, trading latency for performance. And::	0
"me013"::	they were dealing with noise explicitly and we weren't, and::	0
"me013"::	so I think of it as complementary,::	0
"me013"::	that if we can put the -::	0
"me018"::	Think of it as  what?::	0
"me013"::	Complementary.::	0
"me018"::	Hmm.::	0
"me013"::	I think the best systems -::	0
"me013"::	so, uh, everything that we did in- in a  way  it was - it was just::	0
"me013"::	adamantly insisting on going in with a brain damaged system, which is something - actually, we've done a  lot  over the last thirteen years.::	0
"me013"::	Uh,  which is we say, well  this  is the way we should do it. And then we do it. And then::	0
"me013"::	someone else::	0
"me013"::	does something that's straight forward. So, w- th- w- this was a test that largely had additive noise and we did - we adde-::	0
"me013"::	did absolutely nothing explicitly to handle ad- additive noise.::	0
"me018"::	Right.::	0
"me013"::	We just, uh, you know, trained up systems::	0
"me013"::	to be more discriminant.::	0
"me013"::	And, uh, we did this, uh, RASTA-like filtering which::	0
"me013"::	was done in the log domain and was tending to handle convolutional noise. We did - we actually did nothing about additive noise.::	0
"me013"::	So, um,::	0
"me013"::	the, uh, spectral sub- subtraction schemes a couple places did seem to- seem to do a nice job. And so, uh,::	0
"me013"::	we're talking about putting - putting some of that  in  while still keeping some of our stuff. I think you should be able to end up with a system that's better than::	0
"me013"::	both but clearly the way that we're operating for this  other  stuff  does  involved some latency to - to::	0
"me013"::	get rid of most of that latency. To get down to forty or fifty milliseconds we'd have to throw out most of what we're doing.::	1
"me013"::	And - and, uh, I don't think there's any good reason for it in the application actually. I mean, you're -::	0
"me013"::	you're - you're speaking to a recognizer on a remote server::	0
"me013"::	and, uh, having a - a - a quarter second::	0
"me013"::	for some processing to clean it up. It doesn't seem like it's that::	0
"me013"::	big a deal. These aren't large vocabulary things so the decoder shouldn't take a really long time, and.::	0
"me018"::	Mm-hmm.::	0
"me013"::	So.::	0
"me018"::	And I don't think anybody's gonna notice the difference between a quarter of a second of latency and thirty milliseconds of latency.::	0
"me013"::	No. What - what does - wa- was your experience when you were doing this stuff with, uh, the -::	0
"me013"::	the - the surgical, uh,::	0
"me013"::	uh, microscopes and so forth. Um, how long was it from when somebody, uh,::	0
"me013"::	finished an utterance to when, uh, something started happening?::	0
"me018"::	Um, we had a silence detector, so::	0
"me018"::	we would look for the end of an utterance based on the silence detector.::	0
"me013"::	Mm-hmm.::	0
"me018"::	And I - I can't remember now off the top of my head how many::	0
"me018"::	frames of silence we had to detect before we would declare it to be::	0
"me013"::	Mm-hmm.::	0
"me013"::	Mm-hmm.::	0
"me018"::	the end of an utterance. Um,::	0
"me018"::	but it was, uh,::	0
"me018"::	I would say it was probably around the order of two hundred and fifty milliseconds.::	0
"me013"::	Yeah, and that's when you'd  start::	0
"me013"::	doing things.::	0
"me018"::	Yeah, we did the back trace at that point to get the answer.::	0
"me013"::	Yeah.::	0
"me013"::	Of course that didn't take too long at that point. Yeah.::	1
"me018"::	No, no it was pretty quick.::	0
"me013"::	Yeah, so you - you - so you had a::	0
"me018"::	So -::	0
"me018"::	this w-::	0
"me013"::	so you had a - a quarter second delay before, uh,::	0
"me013"::	plus some little processing time, and then::	0
"me018"::	Right.::	0
"me013"::	the - the microscope would start moving or something.::	0
"me018"::	Right.::	0
"me013"::	Yeah.::	0
"me018"::	Right.::	0
"me013"::	And there's physical inertia there, so probably the - the motion itself was  all  -::	0
"me018"::	And it felt to, uh, the users that it was::	0
"me018"::	instantaneous. I mean, as fast as talking to a person. It -::	0
"me018"::	th- I don't think anybody ever complained about the delay.::	0
"me013"::	Yeah, so you would think as long as it's under half a second or something. Uh, I'm not an expert on that but.::	0
"me018"::	Yeah.::	0
"me018"::	Yeah.::	0
"me018"::	I don't remember the exact numbers but::	0
"me013"::	Yeah.::	0
"me018"::	it was something like that.::	0
"me018"::	I don't think you can really  tell.::	0
"me018"::	A person - I don't think a person can  tell  the difference between,::	1
"me018"::	uh, you know, a quarter of a second and a hundred milliseconds, and -::	1
"me013"::	Yeah.::	0
"me018"::	I'm not even sure if we can tell the difference between a quarter of a second and  half  a second.::	1
"me013"::	Yeah.::	0
"me018"::	I mean it just - it feels so quick.::	1
"me013"::	I mean, basically if you - yeah, if you::	0
"me013"::	said, uh, um,::	0
"me013"::	"what's the, uh, uh - what's the shortest route to the opera?"::	0
"me013"::	and it took half a second to get back to you,  I mean,  it would be f- I mean, it might even be too abrupt. You might have to put in a s- a s-  a delay. Yeah.::	0
"me018"::	Yeah.::	0
"me018"::	Yeah.::	0
"me018"::	I mean, it  may  feel different than talking to a person because when we talk to each other we tend to step on each other's utterances.::	0
"me018"::	So like if I'm asking you a question, you may start answering before I'm even  done.::	0
"me013"::	Yeah.::	0
"me018"::	So it - it would probably feel different but I don't think it would feel::	0
"me013"::	Right.::	0
"me018"::	slow.::	0
"me013"::	Right.::	0
"me013"::	Well, anyway,::	0
"me013"::	I mean, I think -::	0
"me013"::	we  could  cut - we know what else, we could cut down on the neural net time by - by, uh,::	1
"me013"::	playing around a little bit, going more into the past, or something like that. We t- we talked about that.::	1
"me018"::	So is the latency from the neural net caused by how far  ahead  you're looking?::	1
"me013"::	Mm-hmm.::	1
"mn007"::	Mm-hmm.::	0
"me013"::	And there's also - well, there's the neural net and there's also this, uh, uh, multi-frame, uh, uh, K_L_T.::	0
"me018"::	Wasn't there -::	0
"me018"::	Was it in the, uh, recurrent neural nets where they weren't looking ahead at all?::	0
"me013"::	They weren't looking ahead  much.::	0
"me013"::	They p- they looked ahead a little bit.::	0
"me018"::	A little bit. O_K.::	0
"me013"::	Yeah.::	1
"me013"::	Yeah, I mean, you could do this with a recurrent net. And - and then - But you  also  could just, um,::	0
"me013"::	I mean, we haven't  experimented  with this but I  imagine  you could, um,::	0
"me013"::	uh, predict a, uh -::	0
"me013"::	um, a label, uh, from more in the past than in - than - than in the future.::	0
"me013"::	I mean, we've d- we've  done  some stuff with that before. I think it - it works O_K.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	So.::	1
"me018"::	We've always had -  usually  we used the symmetric windows but I don't think -::	0
"me013"::	Yeah, but we've - but we played a little bit with - with asymmetric, guys. You can do it.::	0
"me018"::	Yeah.::	0
"me013"::	So.::	0
"me013"::	So, that's what - that's what you're busy with, s- messing around with this, yeah.::	1
"mn007"::	Uh, yeah.::	0
"me013"::	And, uh,::	0
"fn002"::	Also we were thinking to -::	1
"fn002"::	to, uh, apply the eh, spectral subtraction from Ericsson and to - to change the contextual K_L_T for L_D_A.::	1
"mn007"::	Yeah.::	0
"me013"::	Uh-huh.::	0
"me018"::	Change the what?::	0
"fn002"::	The contextual K_L_T.::	0
"me018"::	I'm missing that last word. Context-::	0
"me013"::	K_ - K_L_T.::	0
"me006"::	Oh. K_L_T.::	0
"fn002"::	K_L_T - K_L_T, I'm sorry.::	0
"me018"::	K_L_T. Oh, K_L_T. Uh-huh.::	0
"me013"::	Mm-hmm.::	0
"fn002"::	Uh, to change and use L_D_A discriminative.::	1
"mn007"::	Yeah.::	0
"fn002"::	But -::	0
"me013"::	Uh- huh.::	0
"fn002"::	I don't know.::	0
"me013"::	Uh,::	0
"me018"::	What is the advantage of that?::	0
"fn002"::	Uh -::	0
"mn007"::	Well, it's that by the- for the moment we have, uh, something that's discriminant and nonlinear.::	0
"mn007"::	And the other is linear but it's not discriminant at all. Well, it's::	0
"mn007"::	it's a linear  transformation,  that -::	0
"mn007"::	Uh -::	0
"me013"::	So at least just to understand maybe what the difference was between how much you were getting from::	0
"me013"::	just putting the frames together and how much you're getting from the discriminative,::	0
"me013"::	what the nonlinearity does for you or doesn't do for you.::	0
"me013"::	Just to understand it a little better I guess.::	0
"mn007"::	Mmm.::	0
"mn007"::	Well - uh - yeah.::	0
"mn007"::	Actually what we want to do, perhaps it's to replace - to - to have something that's discriminant but linear, also.::	0
"mn007"::	And to see if it - if it improves ov- over - over the non-discriminant linear transformation.::	0
"mn007"::	And if the neural net is better than this or, well.::	0
"me018"::	Hmm.::	0
"me013"::	Yeah, well, that's what I meant, is to see whether -::	0
"mn007"::	So.::	0
"mn007"::	Ye-::	0
"me013"::	whether it - having the neural net really buys you anything.::	0
"mn007"::	Mmm.::	0
"me013"::	Uh, I mean, it doe-  did  look like it buys you something over just the K_L_T.::	0
"me013"::	But maybe it's just the discrimination and - and maybe - yeah, maybe the nonlinear discrimination isn't necessary.::	0
"mn007"::	Yeah.::	1
"fn002"::	S- maybe.::	0
"mn007"::	Yeah. Mm-hmm.::	1
"me013"::	Could  be.::	0
"fn002"::	Maybe.::	0
"me013"::	Good - good to know.::	0
"me013"::	But the  other  part you were saying was the spectral subtraction, so you just kind of, uh -::	0
"mn007"::	Yeah.::	0
"me013"::	At what stage do you  do  that? Do you - you're doing that, um - ?::	0
"mn007"::	So it would be on the um -::	0
"fn002"::	We was think-::	0
"mn007"::	on - on the mel frequency bands, so. Yeah, be- before  everything.::	1
"fn002"::	Yeah, we - no - nnn::	0
"me013"::	O_K, so just do that on the mel f-::	0
"fn002"::	We - we was thinking to do before after V_A_D or-::	0
"fn002"::	Oh,  we don't know exactly when it's better. Before after V_A_D or -::	0
"mn007"::	Yeah, um -::	0
"fn002"::	and then::	0
"me013"::	So - so you know that - that - that the way that::	0
"mn007"::	Um.::	0
"me013"::	they're - uh,  one  thing that would be no - good to find out about from this conference call is that what they were  talking  about, what they're  proposing  doing,::	1
"me013"::	was having a third party, um,::	0
"me013"::	run a good V_A_D,::	0
"me013"::	and - and determine boundaries.::	1
"fn002"::	Yeah.::	0
"me013"::	And then given those boundaries,::	1
"fn002"::	Begin to work.::	0
"me013"::	then have everybody do the recognition.::	1
"me013"::	The  reason  for that was that, um, uh -::	0
"me013"::	if some- one p- one group put in the V_A_D and another  didn't,::	0
"me013"::	uh, or one had a  better  V_A_D than the other::	0
"me013"::	since that - they're not viewing  that  as being::	0
"me013"::	part of the - the  task,::	0
"me013"::	and that any - any manufacturer would::	0
"me013"::	put a bunch of effort into having some s- kind of good speech-silence detection.::	0
"me013"::	It still wouldn't be  perfect  but I mean,::	0
"me013"::	e- the argument was "let's not have that be part of this test."::	0
"me013"::	"Let's - let's separate that out."::	0
"me013"::	And so,::	0
"me013"::	uh, I guess they argued about that yesterday and,::	1
"me013"::	yeah, I'm sorry, I don't - don't know the answer but we should find out. I'm sure we'll find out soon::	1
"me013"::	what they, uh - what they decided.::	0
"me013"::	So, uh - Yeah, so there's the question of the V_A_D but otherwise it's - it's on the - the, uh - the mel fil- filter bank, uh,::	0
"me013"::	energies I guess? You do - doing the - ?::	0
"fn002"::	Mm-hmm.::	0
"mn007"::	Mmm, yeah.::	0
"fn002"::	Mm-hmm.::	0
"me013"::	And you're - you're subtracting in the - in the - in the -::	0
"me013"::	I guess it's power - power domain,::	0
"me013"::	uh, or - or magnitude domain. Probably power domain, right?::	0
"me013"::	why::	0
"mn007"::	I guess it's power domain, yeah. I don't remember exactly.::	0
"fn002"::	I don't remember.::	0
"me013"::	Yeah,  yep.::	0
"mn007"::	But - yeah, so it's before everything else, and -::	0
"me013"::	I mean, if you look at the theory, it's - it  should  be in the power domain but - but, uh, I've seen implementations where people do it in the magnitude domain and -::	0
"mn007"::	Yeah.::	0
"mn007"::	Mmm.::	0
"me013"::	I have asked people  why  and they shrug their shoulders and say, "oh, it works." So.::	0
"mn007"::	Yeah.::	0
"me013"::	Uh, and there's this - I guess there's this mysterious - I mean people who do this a lot I guess have developed little tricks of the trade. I mean, there's -::	0
"me013"::	there's this, um - you don't just subtract the - the estimate of the noise spectrum. You subtract th- that  times  -::	0
"mn007"::	A little bit more and -::	0
"me013"::	Or - or  less,  or -::	0
"mn007"::	Yeah.::	0
"mn007"::	Yeah.::	0
"me018"::	Really? Huh!::	0
"me013"::	Yeah.::	0
"mn007"::	And generated this - this, um,::	1
"me013"::	Uh.::	0
"mn007"::	so you have the estimation of the power spectra of the noise,::	0
"mn007"::	and you multiply this by a factor which is depend- dependent on the S_N_R.::	0
"fn002"::	Hmm,  maybe .::	0
"mn007"::	So. Well.::	0
"me018"::	Hmm!::	0
"mn007"::	When the speech lev- when the signal level is more important, compared to this noise level,::	0
"mn007"::	the coefficient is small, and around one.::	0
"mn007"::	But when the power le- the s- signal level is::	0
"mn007"::	uh small compared to the noise level, the coefficient is more important.::	0
"mn007"::	And this reduce actually the music- musical noise, uh::	0
"me018"::	Oh!::	0
"mn007"::	which is more important during silence portions, when::	0
"me018"::	Uh-huh.::	0
"mn007"::	the s- the energy's small.::	0
"me018"::	Hmm!::	0
"mn007"::	So there are tricks like this but, mmm.::	1
"me018"::	Hmm!::	0
"me013"::	Yeah.::	0
"me013"::	So.::	0
"mn007"::	Yeah.::	0
"me018"::	Is the estimate of the noise spectrum a  running  estimate?::	0
"mn007"::	Yeah.::	0
"me013"::	Yeah.::	0
"me018"::	Or -::	0
"mn007"::	Yeah.::	1
"me013"::	Well, that's - I mean, that's what differs from different -::	0
"me013"::	different tasks and different s- uh, spectral subtraction methods. I mean, if -::	0
"me018"::	Hmm!::	0
"me013"::	if you have, uh, fair assurance that, uh,::	0
"me013"::	the noise is - is quite stationary,::	0
"me013"::	then the smartest thing to do is use as much::	0
"me013"::	data as  possible  to estimate the noise, get a much better estimate, and subtract it off.::	0
"me018"::	Mm-hmm.::	0
"me013"::	But if it's varying at all, which is gonna be the case for almost any real situation, you have to::	0
"me013"::	do it on-line, uh, with some forgetting factor or something.::	0
"me018"::	So do you - is there some long window that extends into the past over which you calculate the average?::	0
"me013"::	Well, there's a lot of different ways of computing the noise spectrum. So one of the things::	1
"me013"::	that, uh, Hans-Guenter  Hirsch  did, uh - and pas- and other people - actually, he's - he wasn't the only one I guess,::	0
"me013"::	was to, uh, take some period of - of - of speech::	0
"me013"::	and in each band, uh, develop a histogram.::	0
"me013"::	So, to get a decent histogram of these energies::	0
"me013"::	takes at least a few seconds really. But, uh - I mean you can  do  it with a smaller amount but it's pretty rough.::	0
"me013"::	And, um, in  fact  I think the NIST::	0
"me013"::	standard method of determining signal-to-noise ratio is based on this.::	0
"me013"::	So -::	0
"me018"::	A couple seconds?::	0
"me013"::	No, no, it's based on this kind of method, this histogram method.  So you have a  histogram.::	0
"me018"::	Hmm.::	0
"me013"::	Now, if you have  signal  and you have  noise,  you basically have these two  bumps::	0
"me013"::	in the histogram, which you could approximate as two Gaussians.::	0
"me018"::	But wh- don't they overlap sometimes?::	0
"me013"::	Oh,  yeah.::	0
"me018"::	O_K.::	0
"me013"::	So you have a mixture of two  Gaussians.::	0
"me018"::	Yeah.::	0
"me013"::	Right? And you can use E_M to figure out what it  is.  You know. So - so basically now you have this mixture of two Gaussians, you - you n- know what they are, and, uh - I mean, sorry, you estimate what they are,::	0
"me018"::	Yeah.::	0
"me013"::	and, uh, so this gives you what the signal is and what the  noise  e- energy is::	0
"me013"::	in that band in the  spectrum.  And then you look over the whole thing and now you have a noise spectrum.::	0
"me013"::	So, uh, Hans-Guenter  Hirsch  and others have used that kind of method. And the other thing to do::	0
"me013"::	is - which is sort of more trivial and obvious  - is to, uh,::	0
"me013"::	uh, determine through magical means that - that, uh, there's no speech in some period, and then see what the spectrum is.::	0
"me018"::	Mm-hmm.::	0
"me013"::	Uh,  but,::	0
"me013"::	you know, it's - that - that - that's::	0
"me013"::	tricky to do. It has mistakes. Uh, and if you've got enough time, uh, this other method appears to be somewhat more reliable.::	0
"me013"::	Uh, a variant on that for just determining signal-to-noise ratio::	0
"me013"::	is to just, uh - you can do a w- a uh - an iterative thing, E_M-like thing, to determine means only. I guess it is E_M still, but just - just determine the means only.::	0
"me013"::	Don't worry about the variances. And then you just use those mean values as being the - the, uh::	0
"me018"::	Mm-hmm.::	0
"me013"::	uh::	0
"me013"::	signal-to-noise ratio in that band.::	0
"me018"::	But what is the -::	0
"me018"::	it seems like this kind of thing could add to the latency.::	1
"me018"::	I mean, depending on::	1
"me018"::	where the window was that you used to calculate  the signal-to-noise ratio.::	1
"mn007"::	Yeah, sure.::	0
"mn007"::	But -::	0
"mn007"::	Mmm.::	0
"me013"::	Not necessarily. Cuz if you don't look into the future, right?  if you just - yeah - I mean, if you just - if you -::	1
"me018"::	O_K, well that - I guess that was my question, yeah.::	0
"me013"::	you, uh - a- at the beginning you have some -::	0
"me018"::	Guess.::	0
"me013"::	esti- some guess and - and, uh, uh -::	0
"mn007"::	Yeah, but it -::	0
"me013"::	It's an interesting question. I wonder how they did::	0
"mn007"::	Actually, it's a mmm -::	1
"me013"::	do it?::	0
"mn007"::	If- if you want to have a good estimation on non-stationary noise you have to look in the - in the  future.  I mean,::	1
"mn007"::	if you take your window and build your histogram in this window,::	0
"mn007"::	um, what you can expect is to have an estimation of th- of the noise in - in the middle of the window, not at the end. So -::	1
"fn002"::	Mm-hmm.::	0
"me013"::	Well, yeah, but what does - what - what - what does Alcatel do? And - and France Telecom.::	1
"mn007"::	the - but - but people -::	0
"mn007"::	The-::	0
"mn007"::	They just look in the past. I guess it works because the noise are, uh::	1
"mn007"::	pret- uh, almost stationary but,::	1
"me013"::	Pretty stationary.::	0
"me006"::	Pretty stationary, yeah.::	0
"me013"::	Well, the thing, e- e- e- e-::	0
"mn007"::	um -::	0
"me013"::	Yeah, y- I mean, you're talking about non-stationary noise but I think that spectral subtraction is rarely - is - is not gonna work really well for - for non-stationary noise, you know?::	1
"mn007"::	Well, if y- if you have a good estimation of the noise,  yeah,  because well it- it  has  to work. i-::	0
"me013"::	But it's hard to - but that's hard to do.::	1
"mn007"::	Yeah, that's hard to do. Yeah.::	1
"me013"::	Yeah. So - so I think that - that what - what is -::	0
"mn007"::	But -::	0
"me013"::	wh- what's more common is that you're going to be helped with r- slowly varying or stationary noise.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	That's what spectral subtraction will help with, practically speaking.::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	If it varies a  lot,  to get a- If - if - to get a good estimate you need a few seconds of  speech,   even  if it's  centered,::	0
"me013"::	right?  if you need a few seconds to get a decent estimate but it's changed a lot in a few seconds,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	then it, you know, i- it's kind of a problem. I mean, imagine e- five hertz is the middle of the - of the speech modulation spectrum, right?::	0
"mn007"::	Yeah.::	0
"mn007"::	Mmm.::	0
"me013"::	So imagine a jack hammer going at five hertz.::	0
"mn007"::	Yeah, that's -::	0
"me013"::	I mean, good - good  luck.  So,::	0
"mn007"::	So in this case, yeah, sure, you cannot -::	0
"me013"::	Yeah.::	1
"mn007"::	But I think y- um,::	0
"mn007"::	Hirsch does experiment with windows of::	0
"mn007"::	like between five hundred milliseconds and one second. And::	0
"mn007"::	well, five hundred wa- was not so bad. I mean::	0
"mn007"::	and he worked on non-stationary noises, like noise modulated with::	0
"mn007"::	well, wi- with amplitude modulations and::	0
"mn007"::	things like that, and -::	0
"me018"::	Were his, uh, windows centered around the -::	0
"mn007"::	But -::	0
"mn007"::	Um,::	0
"mn007"::	yeah. Well, I think - Yeah. Well, in - in the paper he showed that actually the estimation of the noise is - is delayed. Well, it's - there is -::	1
"mn007"::	you - you have to center the window, yeah.::	0
"me013"::	Yeah.::	0
"mn007"::	Mmm.::	0
"me013"::	No, I understand it's better to  do  but I just think that - that, uh,::	0
"mn007"::	Mmm.::	0
"me013"::	for  real  noises wh- what - what's  most  likely to happen is that there'll be some things that are relatively stationary where you can use one or another spectral subtraction thing and  other  things where it's not so stationary and -::	0
"mn007"::	Yeah.::	0
"me013"::	I mean, you can always pick something that - that falls between your methods, uh, uh, but I don't know if, you know, if sinusoidally, uh,::	0
"mn007"::	Hmm.::	0
"me013"::	modul- amplitude modulated noise is - is sort of a big problem in - in in - practice. I think that  it's uh -::	0
"mn007"::	Yeah.::	0
"me018"::	We could  probably  get a  really  good estimate of the noise if we just went to the  noise  files,::	0
"me018"::	and built the averages from  them.::	0
"me013"::	Yeah.::	0
"me013"::	Well.::	0
"mn007"::	What -::	0
"mn007"::	What do you  mean?::	0
"me013"::	Just cheat - You're saying,  cheat.::	0
"mn007"::	But if the - if the noise is stationary::	0
"me013"::	Yeah.::	0
"me013"::	Yeah.::	1
"mn007"::	perhaps you don't even  need  some kind of noise estimation algorithm. We just take th- th-::	0
"mn007"::	th- the beginning of the utterance and::	0
"me013"::	Oh, yeah, sure.::	0
"mn007"::	I- I know p- I don't know if people tried this for Aurora. Well, everybody seems to use some kind of adaptive, well,::	0
"fn002"::	It's the same.::	0
"fn002"::	Yeah.::	0
"me013"::	But - but -::	0
"mn007"::	scheme but,::	0
"fn002"::	A dictionary.::	0
"me013"::	you know,  stationary  -::	0
"mn007"::	is it very useful and is the c-::	0
"me018"::	Very slow adaptation.::	0
"me013"::	Right, the word "stationary" is - has a very precise statistical meaning. But, you know, in - in signal-processing really what we're talking about I think is things that change slowly,::	0
"me018"::	th-::	0
"me013"::	uh, compared with our - our processing techniques. So::	0
"mn007"::	Mm-hmm.::	0
"me013"::	if you're driving along in a car I - I would think that most of the time::	0
"me013"::	the nature of the noise is going to change relatively slowly. It's not gonna stay absolute the same. If you - if you check it out,::	0
"me013"::	uh, five minutes later you may be in a different part of the road or::	0
"mn007"::	Mm-hmm.::	0
"me013"::	whatever. But it's - it's - i- i- i-::	0
"me013"::	using the local::	0
"me013"::	characteristics in time, is probably going to work pretty well.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	But you could get hurt a lot if you just took some- something from the beginning of all the speech, of, you know, an hour of speech and then later -::	1
"mn007"::	Yeah.::	0
"me013"::	Uh, so they may be - you know, may be  overly,  uh, complicated for - for this test but -::	0
"me013"::	but - but, uh,  I  don't know.::	0
"me013"::	But what you're saying, you know, makes sense, though. I mean, if possible you shouldn't -::	0
"me013"::	you should - you should make it, uh, the center of the - center of the window. But -::	0
"me013"::	uh, we're  already  having problems with these delay, uh -  delay issues. So, uh, we'll have to figure ways  without  it.::	0
"mn007"::	Yeah, so.::	0
"me013"::	Um,::	0
"me018"::	If they're going to provide a,::	0
"me018"::	uh, voice activity detector::	0
"me018"::	that will tell you the boundaries of the speech, then,::	0
"me018"::	couldn't you just go outside those boundaries and do your estimate there?::	0
"me013"::	Oh, yeah.::	0
"me013"::	You  bet.::	0
"me013"::	Yeah.  So I - I imagine that's what they're  doing,  right? Is they're -::	0
"me013"::	they're probably looking in nonspeech sections and getting some, uh -::	1
"mn007"::	Yeah, they have some kind of threshold on - on the previous estimate, and -  So.::	0
"me013"::	@@::	0
"mn007"::	Yeah.::	0
"mn007"::	I  think.  Yeah, I think::	0
"mn007"::	Ericsson used this kind of threshold. Yeah, so, they h- they have an estimate of the noise level::	0
"mn007"::	and they put a threshold like six or ten D_B above,::	0
"mn007"::	and::	0
"mn007"::	what's under this threshold is used to update the estimate.::	0
"mn007"::	Is - is that right or - ?::	0
"fn002"::	Yeah.::	0
"fn002"::	I think so.::	0
"fn002"::	I have not here the proposal.::	0
"mn007"::	So it's - it's - Yeah.::	0
"me013"::	Does France Telecom do this -::	1
"mn007"::	It's like saying what's under the threshold is silence, and -::	0
"me006"::	Hmm.::	0
"me013"::	Does France Telecom do th- do the same thing?::	0
"me013"::	More or less?::	0
"mn007"::	I d- I -::	0
"mn007"::	Y- you know, perhaps?::	0
"fn002"::	No.::	0
"fn002"::	I do- I have not here the proposal.::	0
"me013"::	O_K.::	1
"me013"::	Um,::	0
"me013"::	O_K, if we're - we're done - done with that, uh,::	0
"me013"::	let's see. Uh, maybe we can talk about a couple other things briefly, just, uh, things that - that we've been::	1
"me013"::	chatting about  but  haven't made it into these meetings yet. So you're coming up with your quals proposal, and, uh - Wanna just::	1
"me013"::	give a two three minute summary of what you're planning on doing?::	0
"me006"::	Oh, um,::	0
"me006"::	two, three, it can be shorter than that. Um.::	0
"me013"::	Yeah.::	0
"me006"::	Well, I've -::	0
"me006"::	I've talked to some of you already. Um, but I'm, uh, looking into extending the work done by Larry Saul and John Allen and uh Mazin Rahim.::	1
"me006"::	Um, they - they have a system that's, uh, a multi-band, um, system but their multi-band::	1
"me006"::	is - is a little different than the way that we've been doing multi-band in the past, where::	1
"me006"::	um - Where  we've  been::	0
"me006"::	@@::	0
"me006"::	uh taking  um::	0
"me006"::	sub-band features and i- training up these neural nets and - on - on phonetic targets, and then combining them some- somehow down the line,::	1
"me006"::	um,::	0
"me006"::	they're - they're taking sub-band features and, um,::	1
"me006"::	training up a detector that detects for, um,::	0
"me006"::	these phonetic features::	1
"me006"::	for example, um, he presents um,::	0
"me006"::	uh, a detector to detect sonorance.::	0
"me006"::	And so what - what it  basically  is - is, um - it's - there's -::	0
"me006"::	at the lowest level, there - it's - it's an  OR  ga- I mean, it's an  AND  gate. So, uh, on each sub-band you have several::	0
"me006"::	independent tests,::	0
"me006"::	to test whether::	0
"me006"::	um, there's the existence of sonorance in a sub-band.::	0
"me006"::	And then, um, it c- it's combined by a soft AND gate.::	0
"me006"::	And at the - at the  higher  level,::	0
"me006"::	for every - if, um - The  higher  level there's a soft  OR  gate.::	0
"me006"::	Uh, so if - if this detector detects::	0
"me006"::	um, the presence of - of sonorance in any of the sub-bands, then the detect- uh, the  OR  gate at the top says, "O_K, well this frame::	0
"me006"::	has evidence of sonorance." And these are all -::	0
"me018"::	What are - what are some of the low level detectors that they use?::	0
"me006"::	Oh, O_K. Well, the low level detectors are logistic regressions.::	0
"me006"::	Um, and the, uh - the one o-::	0
"me013"::	So  that,  by the way, basically is a - is one of the units in our - in our - our neural network. So that's all it is. It's a sig- it's a sigmoid,::	0
"me006"::	Yeah.::	0
"me013"::	uh, with weighted sum at the input,::	0
"me018"::	Hmm.::	0
"me006"::	Right.::	0
"me013"::	which you train by gradient  descent.::	0
"me006"::	Yeah, so he uses, um, an E_M algorithm to -::	0
"me006"::	to um train up these um parameters for the logistic regression.::	0
"me006"::	The -::	0
"me013"::	Well, actually, yeah, so I was using E_M to get the  targets.::	0
"me013"::	So - so you have this - this - this AND gate - what we were calling an AND gate, but it's a product - product rule thing at the output.::	0
"me013"::	And then he uses, uh, i- u- and then feeding  into  that are - I'm sorry, there's - it's an  OR  at the output, isn't it? Yeah, so  that's  the product. And then, um,::	0
"me006"::	Mm-hmm.::	0
"me013"::	then he has each of these  AND  things. And, um,::	0
"me013"::	but - so they're little  neural  -  neural  units.::	0
"me013"::	Um, and, um, they have to have  targets.  And so the  targets  come from E_M.::	0
"me018"::	And so are each of these, low level detectors  - are they, uh -::	0
"me018"::	are these something that you decide  ahead  of time, like "I'm going to look for this particular feature or I'm going to look at this frequency," or -::	0
"me018"::	What - what - what are they  looking  at? What are their  inputs?::	0
"me006"::	Um -::	0
"me006"::	Uh-::	0
"me006"::	Right, so the - O_K, so at each- for each sub-band::	0
"me006"::	there are basically, uh, several measures of S_N_R and - and correlation.::	0
"me018"::	Ah, O_K, O_K.::	0
"me006"::	Um, um and he said there's like twenty of these per - per sub-band.::	0
"me006"::	Um,::	0
"me006"::	and for - for every s- every sub-band,::	0
"me006"::	e- you - you just::	0
"me006"::	pick ahead of time, um, "I'm going to have like five::	0
"me006"::	i- independent logistic tests."::	0
"me018"::	Mm-hmm.::	0
"me006"::	And you initialize these parameters,::	0
"me006"::	um, in some - some way::	0
"me006"::	and use E_M::	0
"me006"::	to come up with your training targets for a - for the - the low-level detectors.::	0
"me018"::	Mm-hmm.::	0
"me006"::	And then, once you get that done, you - you - you train the whole -::	0
"me006"::	whole thing on maximum likelihood.  Um,::	0
"me006"::	and h- he shows that using this - this method to detect sonorance is-::	1
"me006"::	it's very robust compared to, um -::	0
"me006"::	to typical, uh, full-band::	0
"me006"::	Gaussian mixtures um estimations of - of sonorance.::	1
"me018"::	Mm-hmm.::	0
"me018"::	Mm-hmm.::	0
"me006"::	And, uh so -::	0
"me006"::	so that's just - that's just one detector. So you can imagine::	1
"me006"::	building many of these detectors on different features. You get enough of these detectors together,::	1
"me006"::	um, then you have enough information to do, um, higher level discrimination, for example, discriminating between phones::	1
"me018"::	Mm-hmm.::	0
"me006"::	and then you keep working your way up until you - you build a full recognizer.::	1
"me018"::	Mm-hmm.::	0
"me006"::	So, um, that's - that's the direction::	1
"me006"::	which I'm - I'm thinking about going in my quals.::	1
"me018"::	Cool.::	0
"me013"::	You know, it has a number of properties that I really liked. I mean, one is the going towards, um,::	0
"me013"::	using narrow band information for, uh, ph- phonetic features of some sort rather than just, uh,::	0
"me013"::	immediately going for the - the typical sound units.::	0
"me018"::	Right.::	0
"me013"::	Another thing I like about it is that you t- this thing is going to be trained -::	0
"me013"::	explicitly  trained for a product of errors rule,::	0
"me013"::	which is what, uh, Allen keeps pointing out that Fletcher observed in the twenties,::	0
"me018"::	Mm-hmm.::	0
"me013"::	uh, for  people  listening to narrow band stuff. That's Friday's talk, by the way.::	0
"me013"::	And then, um,::	0
"me013"::	Uh, the  third  thing I like about it is,::	0
"me013"::	uh, and we've played around with this in a different kind of way a  little  bit but it hasn't been our dominant way of - of operating anything,::	0
"me013"::	um, this issue of where the targets come from.::	0
"me013"::	So in  our  case when we've been training it multi-band things, the way we get the targets for the individual bands::	0
"me013"::	is, uh, that we get the phonetic label -::	0
"me013"::	for the  sound  there and we say, "O_K, we train every -"  What  this  is saying is, O_K, that's maybe what our  ultimate  goal is - or not ultimate but::	0
"me018"::	Mm-hmm.::	0
"me013"::	penultimate  goal is getting these - these small sound units. But - but, um,::	0
"me013"::	along the way how much should we, uh -::	0
"me013"::	uh, what should we be training these  intermediate  things  for?::	0
"me013"::	I mean, because, uh, we don't know::	0
"me013"::	uh, that this is a particularly good feature. I mean, there's no way, uh - someone in the audience yesterday was asking, "well couldn't you have people go through and mark the individual bands and say where the -::	0
"me013"::	where it was sonorant or not?"::	0
"me018"::	Mm-hmm.::	0
"me013"::	But, you know, I think having a bunch of people listening to critical band wide,::	0
"me013"::	uh, chunks of speech trying to determine whether -  I think it'd be  impossible.  It's  all  gonna sound like - like  sine  waves to you, more or  less.  I mean - Well not- I mean, it's g- all g- narrow band::	0
"me006"::	Ouch.::	0
"me018"::	Mm-hmm.::	0
"me013"::	uh, i- I m- I think it's very hard for someone to - to - a person to make that determination. So, um, um, we don't really  know  how those should be labeled.::	0
"me013"::	It could sh- be that you should,::	0
"me013"::	um,::	0
"me013"::	not be paying that much attention to, uh, certain bands for certain sounds, uh, in order to get the::	0
"me018"::	Mm-hmm.::	0
"me013"::	best result. So, um, what we have been doing::	0
"me013"::	there, just sort of mixing it all  together,  is certainly much - much  cruder  than that. We trained these things up on the - on the, uh- the final label. Now we  have::	0
"me013"::	I guess done experiments - you've probably done stuff where you have,::	0
"me013"::	um, done separate, uh, Viterbis on the different -::	0
"me006"::	Yeah. Forced alignment on the sub-band labels? Yeah.::	0
"me013"::	Yeah.::	0
"me013"::	You've done that. Did - did that  help  at all?::	0
"me006"::	Um, it helps for one or t- one iteration but::	0
"me006"::	um, anything after that::	0
"me006"::	it doesn't help.::	0
"me013"::	So - so that may or  may  t- it - that aspect of what he's doing may or may not be helpful because in a  sense  that's the same sort of thing. You're taking global information and determining what you - how you should -  But this is - this is, uh, I th- I think a little more direct.::	1
"me013"::	And -::	0
"me018"::	How did they measure the performance of their detector?::	0
"me013"::	Well, he's look- he's just actually looking at, uh, the confusions between sonorant and non-sonorant.::	0
"me018"::	Mm-hmm.::	0
"me013"::	So he hasn't applied it to recognition or if he did he didn't talk about it. It's - it's just -::	0
"me013"::	And one of the concerns in the audience, actually, was that - that, um,::	0
"me013"::	the, uh, uh - he - he did a comparison to, uh,::	0
"me013"::	you know, our old foil, the - the nasty old standard recognizer with  mel - mel filter bank at the front, and H_M_Ms, and - and so forth.::	1
"me013"::	And, um, it didn't do nearly as  well,  especially in - in  noise.::	0
"me013"::	But the - one of the good questions in the audience was, well, yeah, but that wasn't  trained  for that. I mean,::	0
"me013"::	this use of a very smooth, uh, spectral envelope is something that, you know, has evolved as being generally a good thing for speech recognition::	0
"me013"::	but if you  knew  that what you were gonna do is detect  sonorants  or not - So sonorants and non-sonorants is - is -::	0
"me013"::	is almost like voiced-unvoiced, except I guess that the voiced stops are -::	0
"me013"::	are also called "obstruents". Uh, so it's -::	0
"me013"::	it's - uh, but with the exception of the  stops  I guess it's pretty much the same as voiced-unvoiced, right? So - so -::	0
"me018"::	Mm-hmm.::	0
"me013"::	Um. So, um,::	0
"me013"::	if you  knew  you were doing that, if you were doing something say for a - a, uh - a - a  Vocoder,::	0
"me013"::	you wouldn't  use  the same kind of features. You  would  use something that was sensitive to the periodicity and - and not just the envelope.::	0
"me013"::	Uh, and so in that sense it was an unfair test. Um,::	0
"me013"::	so I think that the questioner was  right.  It - it was in that sense an unfair test. Nonetheless, it was one that was  interesting  because,::	0
"me013"::	uh, this  is  what we are actually using for speech recognition, these smooth envelopes. And::	0
"me013"::	this says that perhaps even, you know, trying to use them in the best way that we  can,  that - that - that we ordinarily  do,  with,::	0
"me013"::	you know, Gaussian mixtures and H_M_Ms  and so forth, you - you don't, uh, actually  do  that well on determining whether something is  sonorant  or not. Which means you're gonna make errors between similar sounds that are son- sonorant or obstruent.::	0
"me018"::	Didn't they -::	0
"me018"::	Didn't they also do some kind of an oracle experiment::	0
"me018"::	where they said "if we  could detect the sonorants perfectly  and then show how it would improve::	0
"me018"::	speech recognition?::	0
"me018"::	I  thought  I remember hearing about an experiment like that.::	0
"me013"::	The- these same people? I don't  remember  that.::	0
"me018"::	Mm-hmm.::	0
"me018"::	Hmm.::	0
"me013"::	That would - that's - you're right, that's exactly the question to follow up this discussion, is suppose you did that, uh, got that right. Um,::	0
"me013"::	Yeah.::	0
"me018"::	Hmm.::	0
"mn007"::	What could be the other low level detectors, I mean, for -::	0
"mn007"::	Other kind of features, or - ?  in addition to detecting sonorants or - ?::	0
"me006"::	Um -::	0
"mn007"::	Th- that's what you want to - to - to go for also or - ?::	0
"me006"::	What t-::	0
"me006"::	Oh, build other - other detectors on different  phonetic features? Um,::	0
"mn007"::	Other low level detectors?::	0
"mn007"::	Yeah.::	0
"me006"::	uh  Let's see, um,::	0
"me006"::	Yeah, I d- I don't know.::	0
"me006"::	e- Um,::	0
"me006"::	um,::	0
"me006"::	I mean, w- easiest thing would be to go - go do some  voicing  stuff but that's very similar to sonorance.::	0
"mn007"::	Mm-hmm.::	0
"me006"::	Um,::	0
"me018"::	When we - when we talked with John Ohala the other day we made a list of some of the things that w-::	0
"me006"::	Yeah.::	0
"me006"::	Oh! O_K.::	0
"me018"::	like frication,::	0
"me006"::	Mm-hmm.::	0
"me018"::	abrupt closure,::	0
"me006"::	Mm-hmm.::	0
"me018"::	R_coloring, nasality, voicing -::	0
"me013"::	Yeah, so there's a half dozen like that that are -  Now this was coming at it from a different  angle  but maybe it's a good::	0
"me018"::	Uh .::	0
"me006"::	Yeah, nasality.::	0
"me013"::	way to  start.  Uh, these are things which, uh,::	0
"me013"::	John felt that a - a, uh - a  human  annotator::	0
"me013"::	would be able to reliably  mark.::	0
"me006"::	Oh, O_K.::	0
"me013"::	So the sort of things he felt would be  difficult  for a human annotator to reliably mark::	0
"me013"::	would be  tongue  position kinds of things. Yeah.::	0
"me006"::	Placing stuff, yeah.::	0
"me018"::	Mm-hmm.::	0
"me013"::	Uh -::	0
"me018"::	There's also things like stress.::	0
"me018"::	You can look at stress.::	0
"me006"::	Mm-hmm.::	0
"me013"::	But stress::	0
"me013"::	doesn't, uh,::	0
"me013"::	fit in this thing of coming up with features that will distinguish words from one another, right? It's a - it's a good thing to mark and will probably help us ultimate with recognition but -::	0
"me018"::	Yeah, there's a  few  cases where it can like  permit   and  permit.::	0
"me018"::	But - that's not very common in  English.  In  other  languages it's more::	0
"me018"::	uh, important.::	0
"me013"::	Well, yeah, but i- either case you'd write P_E_R_M_I_T, right? So you'd get the  word  right.::	0
"me018"::	No, I'm saying, i- i- e- I thought you were saying that stress doesn't help you distinguish between  words.::	0
"me013"::	Um,::	0
"me018"::	Oh, I see what you're saying. As long as you get -::	0
"me013"::	We're g- if we're doing - if we're talking about  transcription  as opposed to something else -::	0
"me018"::	The  sequence,  right?::	0
"me018"::	Yeah.::	0
"me018"::	Yeah, yeah, yeah. Yeah.::	0
"me013"::	Yeah.::	0
"me018"::	Right.::	0
"me018"::	So where it could help is maybe at a  higher  level. Yeah. Understanding, yeah. Exactly.::	0
"me006"::	Like a understanding application. Yeah.::	0
"me013"::	Right.::	0
"me013"::	Yeah. But that's this  afternoon's  meeting. Yeah.  We don't understand anything in this meeting.::	0
"me013"::	Yeah, so that's - yeah, that's, you know, a neat - neat thing and - and, uh -::	0
"me006"::	S- so, um, Ohala's going to help do these, uh  transcriptions of the meeting data?::	0
"me013"::	So.::	0
"me018"::	Uh, well I don't know. We d- we sort of didn't get that far. Um, we just talked about some::	0
"me018"::	possible features that could be marked::	0
"me018"::	by  humans  and, um,::	0
"me006"::	Hmm.::	0
"me018"::	because of having maybe some extra transcriber time we thought we could go through and mark some portion of the  data  for that.::	0
"me018"::	And, uh -::	0
"me006"::	Hmm.::	0
"me013"::	Yeah, I mean, that's not an immediate problem, that we don't immediately have a lot of extra transcriber time. But - but, uh, in the long term I guess Chuck is gonna continue the dialogue with John and - and, uh,::	0
"me018"::	Yeah, right.::	0
"me013"::	and, we'll - we'll end up doing  some  I think.::	0
"me018"::	I'm definitely interested in this::	0
"me018"::	area, too, f- uh, acoustic feature::	0
"me013"::	Uh-huh.::	0
"me006"::	O_K.::	0
"me018"::	stuff. So.::	0
"me013"::	Yeah, I think it's an interesting - interesting way to go. Um,::	0
"me006"::	Cool.::	0
"me013"::	I say it like "said-int" . I think it has a number of good things.::	0
"me013"::	Um,::	0
"me013"::	so, uh, y- you want to talk maybe a c- two or three minutes about what::	1
"me013"::	we've  been talking about today and other days?::	1
"me026"::	Ri-::	0
"me026"::	Yeah, O_K, so, um,::	0
"me026"::	we're interested in, um, methods for far mike speech recognition, um,  mainly, uh, methods that deal with the reverberation  in the far mike signal. So, um,::	1
"me026"::	one approach would be, um, say M_S_G and P_L_P, like was used in Aurora one and, um,::	1
"me026"::	there are other approaches which actually attempt to   remove  the reverberation, instead of being  robust  to it like M_S_G.::	1
"me026"::	And so we're interested in, um,::	1
"me026"::	comparing the performance of  um, a robust approach like M_S_G with these, um, speech enhancement or  de-reverber-  de-reverberation approaches.::	1
"mn007"::	Mm-hmm.::	0
"me026"::	@@::	0
"me026"::	And, um,::	0
"me026"::	it looks like we're gonna use the Meeting Recorder digits data for that.::	0
"mn007"::	And the de-reverberation algorithm, do you have -::	0
"mn007"::	can you give some more details on this or - ? Does it use one microphone?::	0
"me026"::	o-::	0
"me026"::	o-::	0
"mn007"::	Several microphones? Does it - ?::	0
"me026"::	O_K, well, um,::	0
"me026"::	there was something that was done by, um,::	0
"me026"::	a guy named Carlos, I forget his last name,  who worked with Hynek, who, um,::	0
"me013"::	Avendano.::	0
"me026"::	O_K. Who, um,::	0
"me013"::	Yeah.::	0
"mn007"::	Mm-hmm.::	0
"me026"::	um, it was like RASTA in the sense that of it was, um, de-convolution by filtering::	0
"me026"::	um, except he used a longer  time  window,::	0
"mn007"::	Mm-hmm.::	0
"me026"::	like a  second  maybe. And the reason for that is RASTA's time window is too short to, um::	0
"me026"::	include the whole, um, reverberation -::	0
"me026"::	um, I don't know what you call it  - the reverberation response.::	0
"me026"::	@@::	0
"me026"::	I- if you see wh- if you see what I mean.::	0
"me026"::	The reverberation filter from my mouth to that mike is like - it's t- got- it's too long::	0
"me026"::	in the - in the time domain for the um - for the RASTA filtering to take care of it.::	0
"me026"::	And, um,::	0
"me026"::	then there are a couple of other speech enhancement approaches::	0
"me026"::	which haven't been tried for speech recognition yet but have just been tried for enhancement, which, um,::	0
"me026"::	have the assumption that::	0
"me026"::	um, you can do L_P_C::	0
"me026"::	um::	0
"me026"::	analysis of th- of the signal you get at the far microphone and::	0
"me026"::	the, um, all pole filter that you get out of that should be good.::	0
"me026"::	It's just the, um, excitation signal::	0
"me026"::	that  is  going to be distorted by the reverberation::	0
"me026"::	and so you can try and reconstruct a better excitation signal::	0
"me026"::	and, um, feed  that  through the i-::	0
"me026"::	um, all pole filter and get enhanced speech with reverberation reduced.::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	There's  also  this, uh, um,::	1
"me013"::	uh, echo cancellation stuff that we've sort of been chasing, so, uh::	1
"me013"::	we have, uh - and when we're saying these digits now we  do  have a close microphone signal and then there's the distant microphone signal.::	1
"me013"::	And you  could  as a kind of  baseline  say, "O_K,  given  that we have  both  of these, uh, we  should  be able to do, uh, a  cancellation. "::	1
"me013"::	So that, uh, um,::	1
"me013"::	we - we, uh, essentially identify the system in between - the linear time invariant system between the microphones and - and - and - and re- and invert it,::	1
"me013"::	uh, or - or cancel it out to - to some - some reasonable approximation::	1
"mn007"::	Mm-hmm.::	0
"me013"::	through one method or another. Uh, that's not a  practical  thing,::	0
"me013"::	uh, if you have a distant mike, you  don't  have a close mike ordinarily,  but we thought that might make - also might make a good  baseline.::	0
"me013"::	Uh, it still won't be  perfect  because there's  noise.::	0
"me013"::	Uh,  but  -  And then there are s- uh, there are::	0
"me013"::	single  microphone methods that I  think  people have done for, uh - for this kind of de-reverberation. Do y- do you know any::	0
"me013"::	references to any? Cuz I - I w- I was - w- w- I - I lead him down a - a bad::	0
"mn007"::	Uh,::	0
"me013"::	path on that. But.::	0
"mn007"::	I g- I guess - I guess when people are working with single microphones,::	0
"mn007"::	they are more trying to do -::	0
"mn007"::	well, not - not very -::	0
"mn007"::	Well, there is the Avendano work,::	0
"me013"::	Right.::	0
"mn007"::	but also trying to mmm,::	0
"mn007"::	uh -::	0
"mn007"::	trying to f- t-::	0
"mn007"::	find the de-convolution filter::	0
"mn007"::	but in the um -::	0
"mn007"::	not in the time domain but in the::	0
"mn007"::	uh::	0
"mn007"::	the stream of features  uh I guess .::	0
"me013"::	Yeah, O_K.::	1
"mn007"::	Well,  @@   there - there's someone working on this on::	0
"mn007"::	i- in Mons::	0
"mn007"::	So perhaps, yeah,::	0
"mn007"::	we should try t- to - He's working on this, on trying to -::	0
"me013"::	Yeah.::	0
"mn007"::	on re- reverberation, um -::	0
"me013"::	The  first  paper on this is gonna have  great  references, I can tell already.::	0
"mn007"::	Mm-hmm.::	1
"me013"::	It's  always  good to have references, especially when reviewers read it or - or one of the authors and,::	0
"me013"::	feel  they'll  "You're O_K, you've r- You cited me."::	1
"mn007"::	So, yeah.::	0
"mn007"::	Well, he did  echo cancellation  and he did some fancier  things  like, uh,::	0
"mn007"::	uh, training different network on different reverberation conditions and then trying to find the best one, but. Well.::	0
"me013"::	Yeah.::	0
"mn007"::	Yeah.::	0
"me013"::	The oth- the other thing, uh, that Dave was talking about earlier was, uh, uh, multiple mike things,::	0
"me013"::	uh, where they're  all  distant. So, um, I mean, there's - there's  all  this work on  arrays,  but the  other  thing is, uh,  what can we do that's cleverer::	0
"me013"::	that can take some advantage of only  two  mikes, uh, particularly if there's an obstruction  between  them, as we - as we have over  there.::	0
"mn007"::	If there is - ?::	1
"me013"::	An  obstruction  between them.::	0
"mn007"::	Ah, yeah.::	0
"me013"::	It creates a  shadow  which is - is  helpful.  It's part of why you have such good directionality with,::	0
"me013"::	with two  ears  even though they're not several feet  apart.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	For::	0
"me013"::	most - for  most  people's heads.::	0
"me018"::	That  could  help  though.::	0
"me013"::	So that - Yeah, the - the  head,  in the way, is really -::	0
"me013"::	that's what it's  for.::	0
"me018"::	That's what the head's for?::	0
"me013"::	It's basically,::	0
"me013"::	Yeah, it's to separate the ears.::	0
"me018"::	To separate the ears?::	0
"me013"::	That's right, yeah.::	0
"me013"::	Yeah. Uh, so.::	0
"me013"::	Anyway, O_ K.  Uh, I think that's - that's all we have this week. And, uh, I think it's digit time.::	0
"me006"::	Oh.::	0
"me018"::	Actually the, um - For some reason the digit forms are  blank.::	0
"me013"::	Yeah?::	0
"me018"::	Uh, I think th- that may be due to the fact that::	0
"me013"::	Oh!::	0
"me018"::	Adam ran out of digits,  uh, and didn't have time to regenerate any.::	0
"me013"::	Oh! I guess it's - Well there's no real reason to write our  names  on here then, is there?::	0
"me018"::	Yeah, if you want to put your credit card numbers and, uh -::	0
"me006"::	Oh, no - ?::	0
"me013"::	Or do - did any - do we need the names for the  other  stuff, or - ?::	0
"me018"::	Uh, yeah, I do need your names and - and the time, and all that, cuz we put that into the "key" files. Um.::	0
"me013"::	Oh, O_K.::	0
"me013"::	Oh, O_K.::	0
"me018"::	But w-::	0
"me013"::	O_K.::	0
"me018"::	That's why we have the forms, uh, even if there are no digits.::	0
"me013"::	O_K, yeah, I didn't  notice  this. I'm sitting here and I was - I was about to  read   them    too.   It's a, uh, blank sheet of paper.::	0
"me018"::	So I guess we're - we're done.::	0
"me013"::	Yeah, yeah, I'll do my credit card number  later.  O_K.::	0
