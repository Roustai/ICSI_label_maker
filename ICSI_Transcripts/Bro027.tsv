"mn007"::	Eight, eight?  Three.::	0
"me018"::	O_K, we're  going.::	0
"mn052"::	This is three.::	0
"mn052"::	Yep. Yep.::	0
"me013"::	Test.::	0
"me013"::	Hmm.  Let's see.::	0
"me013"::	Move it bit.  Test?::	0
"me013"::	Test? O_K, I guess it's alright.::	0
"me013"::	So, let's see.::	0
"me013"::	Yeah, Barry's not here and Dave's not here. Um, I can say about -::	0
"me013"::	just q- just quickly to get through it, that Dave and I submitted this A_S_R_U.::	0
"me018"::	This is for A_S_R_U.::	0
"me013"::	Yeah. So.::	0
"me013"::	Um.::	0
"me013"::	Yeah, it's -::	0
"me013"::	it's interesting. I mean, basically we're dealing with rever- reverberation,::	1
"me013"::	and, um, when we deal with pure reverberation, the technique he's using works really, really well.::	1
"me013"::	Uh, and when they had the reverberation  here,  uh, we'll measure the signal-to-noise ratio and it's, uh, about nine D_B.::	0
"me013"::	So, um,::	0
"mn052"::	Hmm.::	0
"me013"::	a fair amount of -::	0
"me018"::	You mean, from the actual, uh, recordings?::	0
"mn052"::	k-::	0
"me013"::	Yeah.::	0
"me018"::	It's nine D_B?::	0
"me013"::	Yeah. Um -::	0
"me013"::	And actually it brought up a question which may be relevant to the Aurora stuff too.::	0
"me013"::	Um, I know that when you figured out the  filters  that we're using for the Mel scale,::	0
"me013"::	there was some experimentation that went on at - at, uh - at O_G_I.::	0
"me013"::	Um,::	0
"me013"::	but one of the differences that we found between the two systems that we were using,  the - the Aurora H_T_K system baseline system::	0
"me013"::	and the system that we were - the - the uh,  other  system we were using, the uh, the S_R_I system,::	0
"me013"::	was that the S_R_I system had maybe a, um, hundred hertz high-pass.::	0
"mn052"::	Yep.::	0
"me013"::	And the, uh, Aurora H_T_K, it was like twenty.::	0
"mn052"::	S- sixty-four.::	0
"me013"::	Uh.::	0
"mn052"::	S- sixty-four.::	0
"me013"::	Sixty-four? Uh.::	0
"mn052"::	Yeah, if you're using the baseline.::	0
"me013"::	Is that the ba- band center?::	0
"mn052"::	No, the edge.::	0
"me013"::	The edge is really, uh, sixty-four? For some reason, uh,::	0
"mn052"::	Yeah .   @@::	0
"mn052"::	So the, uh, center would be somewhere around::	0
"me013"::	Dave thought it was  twenty,  but.::	0
"mn052"::	like hundred and -::	0
"mn052"::	hundred and - hundred - hundred and - maybe - it's like - fi- hundred hertz.::	0
"me013"::	But do you know, for instance, h- how far down it would be at twenty hertz?::	0
"me013"::	What the - how much rejection would there be at twenty hertz, let's say?::	0
"mn052"::	At twenty hertz.::	0
"me013"::	Yeah, any idea what the curve looks like?::	0
"mn052"::	Twenty hertz frequency -::	0
"mn052"::	Oh, it's - it's  zero  at twenty hertz, right? The  filter?::	0
"mn007"::	Yea- actually, the left edge of the first filter is at sixty-four. So -::	0
"mn052"::	Sixt- s- sixty-four. So anything less than sixty-four is zero.::	0
"mn007"::	Mmm.::	0
"me013"::	It's actually set to zero?::	0
"mn052"::	Yeah.::	0
"me013"::	What kind of filter is  that?::	0
"mn007"::	Yeah.::	0
"me013"::	Is this - oh, from the - from -::	0
"mn007"::	It -::	0
"mn007"::	This is the filter bank::	0
"mn007"::	in the frequency domain that starts at sixty-four. Yeah.::	0
"me013"::	Oh, so you, uh - so you really set it to zero, the F_F_T?::	0
"mn052"::	Yeah, yeah. So it's - it's a weight on the  ball  spectrum.::	0
"mn052"::	Triangular weighting.::	0
"me013"::	Right. O_K.::	0
"me013"::	Um -::	0
"me013"::	O_K. So that's - that's a little different than Dave thought, I think. But - but, um,::	0
"me013"::	still,  it's possible that we're getting in some more  noise.::	0
"me013"::	So I wonder, is it -  @@  Was there - their experimentation::	0
"me013"::	with, uh, say, throwing away that filter or something? And, uh -::	0
"mn052"::	Uh, throwing away the first?::	0
"me013"::	Yeah.::	0
"mn052"::	Um, yeah, we - we've tried including the full -  full  bank.::	0
"mn052"::	Right? From zero to four K_.::	0
"mn052"::	And   that's always worse than using sixty-four hertz.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	Right, but the question is, whether sixty-four hertz is - is, uh, too,::	0
"me013"::	uh,  low.::	0
"mn052"::	Yeah, I mean, make it a  hundred  or so?::	0
"me013"::	Yeah.::	0
"mn052"::	I t- I think I've tried a hundred and it was::	0
"mn052"::	more or less the same, or slightly worse.::	0
"me013"::	On what test set?::	0
"mn052"::	On the same, uh, SpeechDat-Car, Aurora.::	0
"me013"::	Um, it  was  on the SpeechDat-Car.::	0
"mn052"::	Yeah.::	0
"mn052"::	So I tried a hundred to four K_. Yeah.::	0
"me013"::	Um,::	0
"mn052"::	So it was -::	0
"me013"::	and on - and on the, um, um,::	0
"me013"::	T_I-digits  also?::	0
"mn052"::	No, no, no. I think I just tried it on SpeechDat-Car.::	0
"me013"::	Mmm. That'd be something to look at sometime because what,::	0
"me013"::	um,::	0
"me013"::	eh, he was looking at was performance in  this  room.::	0
"mn052"::	Mm-hmm.::	0
"me013"::	Would that be more like -::	0
"me013"::	Well, you'd  think  that'd be more like SpeechDat-Car, I guess, in terms of the noise.::	0
"me013"::	The SpeechDat-Car is more, uh, sort of::	0
"me013"::	roughly stationary, a lot of it. And -::	0
"mn052"::	Yeah.::	0
"me013"::	and T_I-digits maybe is not so much as - Yeah.::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	Yeah.::	0
"me013"::	Mm-hmm.::	0
"me013"::	O_K. Well, maybe it's not a big deal.::	0
"me013"::	But, um -::	0
"me013"::	Anyway, that was just something we wondered about.::	0
"me013"::	But, um, uh, certainly a lot of the noise,::	0
"me013"::	uh, is, uh, below a hundred hertz. Uh, the::	0
"mn052"::	Yeah.::	0
"me013"::	signal-to-noise ratio, you know, looks a fair amount better if you - if you high-pass filter it from this room.::	0
"me013"::	But, um - but it's  still  pretty noisy. Even - even for a hundred hertz up, it's - it's still fairly noisy. The signal-to-noise ratio is - is -::	0
"mn007"::	Mm-hmm.::	0
"me013"::	is actually still pretty bad.::	0
"me013"::	So, um, I mean, the main - the - the -::	0
"me018"::	Hmm.::	0
"me018"::	So that's on th- that's on the f- the  far  field ones though, right? Yeah.::	0
"me013"::	Yeah, that's on the far field. Yeah, the near field's pretty good.::	0
"me018"::	So wha- what is, uh - what's  causing  that?::	0
"me013"::	Well, we got a - a video projector in here,::	0
"me013"::	uh, and, uh - which we keep on during every - every session we record, which, you know, I - I -::	0
"me018"::	Yeah.::	0
"me013"::	w- we were aware of but - but we thought it wasn't a bad thing. I mean, that's a::	0
"me018"::	Uh-huh.::	0
"me018"::	Yeah.::	0
"me013"::	nice noise source. Uh, and there's also the, uh - uh, air conditioning.::	0
"me018"::	Hmm.::	0
"me013"::	Which, uh, you know,::	0
"me013"::	is a pretty low frequency kind of thing. But - but, uh -::	0
"me018"::	Mm-hmm.::	0
"me013"::	So, those are - those are major components, I think,::	0
"me018"::	I see.::	0
"me013"::	uh, for the stationary kind of stuff.::	0
"me018"::	Mmm.::	0
"me013"::	Um,::	0
"me013"::	but, um, it, uh - I guess, I - maybe I said this last week too but it - it - it really became apparent to us that we need to - to take account of noise.::	0
"me013"::	And, uh, so I think when - when he gets done with his prelim study I think  one of the next things we'd want to do is to::	0
"me013"::	take this, uh - uh, noise, uh, processing stuff and - and,::	0
"me013"::	uh - uh, synthesize some speech from it. And then -::	0
"me018"::	When are his prelims?::	0
"me013"::	Um, I think in about, um,::	0
"me013"::	a little less than two weeks.::	0
"me018"::	Oh.::	0
"me018"::	Wow.::	0
"me013"::	Yeah.::	0
"me013"::	Yeah. So.::	0
"me013"::	Uh, it might even be sooner. Uh, let's see, this is the sixteenth, seventeenth?::	0
"me013"::	Yeah, I don't know if he's before - It might even be in a week.::	0
"me013"::	A week, week and a half.::	0
"me018"::	So, I- Huh. I - I guessed that they were gonna do it some time during the semester but they'll do it any time, huh?::	0
"me013"::	They seem to be - Well, the semester actually is starting up.::	0
"me018"::	Is it already?::	0
"me013"::	Yeah, the semester's late - late August they start here.::	0
"me018"::	Yikes.::	0
"me013"::	So they do it right at the beginning of the semester.::	0
"me018"::	Yeah.::	0
"me013"::	Yeah.::	0
"me013"::	So, uh - Yep. I mean, that - that was sort of one - I mean,::	0
"me013"::	the overall results seemed to be first place in - in - in the case of either,::	0
"me013"::	um, artificial reverberation::	0
"me013"::	or a modest sized training set.::	0
"me013"::	Uh, either way,::	0
"me013"::	uh, i- uh, it helped a lot.::	0
"me013"::	And - But if you had a - a really big training set,::	0
"me013"::	a recognizer, uh, system that was capable of taking  advantage  of a really large training set -::	0
"me013"::	I thought that -  One thing with the H_T_K is that is has the - as we're  using  - the configuration we're  using::	0
"me013"::	is w- s- is - being bound by the terms of Aurora, we have::	0
"me013"::	all those parameters just set as they  are.  So even if we had a hundred times as much data, we wouldn't::	0
"me013"::	go out to, you know,::	0
"me013"::	ten or t- or a hundred times as many Gaussians or anything. So,::	0
"me013"::	um, it's kind of hard to take advantage of - of - of big chunks of data.::	0
"mn052"::	Mmm, yeah.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	Uh, whereas the other one does sort of expand as you have more training data. It does it automatically, actually.::	0
"me013"::	And so, um,::	0
"me013"::	uh,::	0
"me013"::	that one really benefited from the larger set. And it was also a diverse set with different noises and so forth. Uh,::	0
"me013"::	so, um,::	0
"me013"::	that, uh - that seemed to be - So, if you have that -::	0
"me013"::	that  better  recognizer that can - that::	0
"me013"::	can build up more parameters,::	0
"me013"::	and if you, um, have the natural room, which in this case has a p- a pretty bad signal-to-noise ratio,::	0
"me013"::	then in that case, um, the right thing to do is just do - u- use speaker adaptation.::	0
"me013"::	And - and not bother with - with::	0
"me013"::	this acoustic, uh, processing. But I think that that would::	0
"me013"::	not be true if we did some explicit noise-processing as well as, uh,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	the convolutional kind of things we were doing.::	0
"me013"::	So.::	0
"me013"::	That's sort of what we found.::	0
"mn052"::	Hmm.::	0
"me018"::	I, um -::	1
"me018"::	uh, started working on the::	0
"me018"::	uh -::	0
"me018"::	Mississippi State::	0
"me018"::	recognizer.::	1
"mn052"::	Oh, O_K.::	0
"me018"::	So, I got in touch with Joe and -::	1
"me018"::	and, uh, from your email and things like that. And,::	1
"me018"::	uh, they added me to the list -::	1
"me018"::	uh, the mailing list. And he gave me all of the::	1
"mn052"::	O_K, great.::	0
"me018"::	pointers and everything that I needed. And so I downloaded the, um -::	1
"me018"::	There were two things,::	1
"me018"::	uh, that they had to download.::	1
"me018"::	One was the, uh, I guess the software.::	0
"me018"::	And another  wad   - was a, um,::	0
"me018"::	sort of like a sample - a sample run.::	0
"me018"::	So I downloaded the software and compiled all of that. And it::	1
"mn052"::	Eight.::	0
"me018"::	compiled fine. No problems.::	1
"mn052"::	Oh, eh, great.::	0
"me018"::	And, um, I grabbed the sample stuff but I haven't, uh,::	0
"mn052"::	That sample was released only yesterday or the day before, right?::	0
"me018"::	compiled it.::	0
"me018"::	No - Well, I haven't grabbed  that  one yet. So there's  two.::	0
"mn052"::	Oh, there is  another  short sample set - o- o- sample. O_K.::	0
"me018"::	There was  another   short  one, yeah. And so I haven't grabbed the  latest  one that he just, uh, put out yet.::	0
"mn052"::	Oh, O_K. F- Yeah, O_K.::	0
"me018"::	So.::	0
"me018"::	Um, but, the software seemed to compile fine and everything, so.::	0
"me018"::	And, um,::	0
"me018"::	So.::	0
"me013"::	Is there any word yet about the issues about, um, adjustments for different feature sets or anything?::	1
"me018"::	No, I - I d-::	0
"me018"::	You asked me to write to him and I think I forgot to ask him about that.::	1
"me013"::	Yeah.::	0
"me018"::	Or if I  did  ask him, he didn't reply. I - I don't remember  yet .::	0
"me018"::	Uh, I'll - I'll d- I'll double check that and ask him again.::	1
"me013"::	Yeah.::	0
"me013"::	Yeah, it's like that - that could r- turn out to be an important issue for us. Yeah.::	1
"mn052"::	Hmm. Mmm.::	0
"me018"::	Yeah. Yeah.::	0
"mn052"::	Cuz  they have it -::	0
"me018"::	Maybe I'll send it to the list.::	0
"me018"::	Yeah.::	0
"mn052"::	Cuz they have, uh, already frozen those in i- insertion penalties and all  those  stuff is what - I feel. Because they have this document::	1
"me018"::	Uh-huh.::	0
"mn052"::	explaining the recognizer.::	0
"mn052"::	And they have these tables with,::	1
"mn052"::	uh, various language model weights, insertion penalties.::	1
"mn052"::	u-::	0
"me018"::	O_K, I haven't seen that one yet.::	0
"mn052"::	Uh, it's th- it's there on that web. And, uh, on  that,  I mean, they have run some experiments using various::	0
"me018"::	So.::	0
"me018"::	O_K.::	0
"mn052"::	insertion penalties and all those -::	0
"me018"::	And so they've picked -::	0
"mn052"::	Yeah, I think they pi- p- yeah, they picked the values from -::	0
"me018"::	the values. Oh, O_K. O_K.::	0
"me013"::	For r- w- what test set?::	0
"mn052"::	Uh, p- the one that they have reported is a NIST evaluation, Wall Street Journal.::	0
"me013"::	But that has nothing to do with what we're  testing  on, right?::	0
"mn052"::	You know. No. So they're, like - um -::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	So they are actually trying to, uh,::	0
"mn052"::	fix that - those values using the clean,::	0
"mn052"::	uh, training part of the Wall Street Journal. Which is - I mean, the  Aurora.::	0
"mn052"::	Aurora has a clean subset. I mean, they want to train it and then this - they're going to run some evaluations.::	0
"me013"::	Right.::	0
"me013"::	So they're set- they're setting it based on that?::	0
"mn052"::	Yeah.::	0
"me013"::	O_K. So  now,  we may come back to the situation where::	1
"me013"::	we may be looking for a modification of the features to account for the fact::	0
"me013"::	that we can't modify these parameters. But, um,::	1
"me018"::	Yeah.::	0
"mn052"::	Yeah.::	0
"me013"::	uh - but it's still worth, I think, just - since - you know, just chatting with Joe about the issue.::	1
"me018"::	Yeah, O_K. Do you think that's something I should just send to  him  or do you think I should send it to this - there's an - a m- a mailing  list.::	0
"me013"::	Um -::	0
"me013"::	Well, it's not a  secret.  I mean, we're, you know, certainly willing to talk about it with everybody, but I think - I think that, um -::	0
"me013"::	um, it's probably best to start talking with him just to -::	0
"me018"::	O_K.::	0
"me013"::	Uh  @@   you know, it's a dialogue between two of you about what - you know, what does he  think  about this and what - what - you know - what could be  done  about it. Um,::	0
"me018"::	Yeah.::	0
"me018"::	O_K.::	0
"me013"::	if you get ten people in - involved in it there'll be a lot of perspectives based on, you know, how -::	0
"me018"::	Yeah.::	0
"me013"::	you know. Uh - But, I mean, I think it all  should  come up eventually, but if - if -::	0
"me018"::	Right.::	0
"me018"::	O_K.::	0
"me013"::	if there is any, uh, uh, way to move in - a way that would - that would, you know, be more open to different kinds of::	0
"me013"::	features.  But if - if, uh - if there  isn't,  and it's just kind of shut down and - and then  also  there's probably not::	0
"me013"::	worthwhile bringing it into a larger forum where - where political issues will come in.::	0
"me018"::	Yeah.::	0
"me018"::	O_K.::	0
"mn052"::	Oh.  @@  So this is now - it's - it's compiled under Solaris?::	0
"me018"::	Yeah.::	0
"mn052"::	Yeah, O_K. Because he - there was some mail r- saying that it's - may not be stable for Linux and all those.::	0
"me018"::	Yep.::	0
"me018"::	Yeah.::	0
"me018"::	Yeah, i- that was a particular  version.::	0
"mn052"::	SUSI  yeah.::	0
"me018"::	Yeah,  SUSI  or whatever it was but we don't have that. So.::	0
"mn052"::	Yeah, yeah.::	0
"mn052"::	Yeah, O_K.::	0
"mn052"::	O_K, that's fine. Yeah.::	0
"me018"::	Should  be O_K. Yeah, it compiled  fine  actually. No - no errors. Nothing. So.::	0
"mn052"::	That's  good.::	0
"me013"::	Uh, this is slightly off topic but, uh,::	0
"me013"::	I noticed, just glancing at the, uh, Hopkins::	0
"me013"::	workshop, uh, web site that, uh,::	0
"me013"::	um -::	0
"me013"::	one of the thing- I don't know - Well, we'll see how much they  accomplish,  but one of the things that they were  trying  to do in the::	0
"me013"::	graphical models thing was to put together a - a, uh, tool kit::	0
"me013"::	for doing, uh r- um, arbitrary::	0
"me013"::	graphical models for, uh, speech recognition.::	0
"me018"::	Hmm.::	0
"me013"::	So - And Jeff, uh - the two Jeffs were::	0
"me018"::	Who's the second Jeff?::	0
"me013"::	Uh - Oh, uh, do you know Geoff Zweig?::	0
"me018"::	No.::	0
"me013"::	Oh. Uh, he - he, uh - he was here for a couple years and he, uh - got his P_H_D. He -::	1
"me018"::	Oh, O_K.::	0
"me013"::	And he's, uh, been at I_B_M for the last couple years.::	0
"me018"::	Oh, O_K.::	0
"me013"::	So. Uh, so he did - he did his P_H_D on dynamic Bayes-nets, uh,::	1
"me018"::	Wow.   That  would be neat.::	0
"me013"::	for - for speech recognition. He had some continuity built into the model,::	1
"me013"::	presumably to handle some, um,::	0
"me013"::	inertia in the - in the production system, and,::	0
"me013"::	um -::	0
"me018"::	Hmm.::	0
"me013"::	So.::	0
"mn052"::	Hmm.::	0
"mn007"::	Um, I've been playing with, first, the, um, V_A_D.::	1
"mn007"::	Um,  so it's exactly the same approach, but::	1
"mn007"::	the features that the V_A_D neural network use are, uh, M_F_C_C after noise compensation.::	1
"mn007"::	Oh, I think I have the results.::	0
"me013"::	What was it using before?::	1
"mn007"::	Before it was just::	1
"mn052"::	@@::	0
"mn007"::	P_L_Ps. So.::	1
"mn052"::	Yeah, it  was  actually - No. Not - I mean, it was just the noisy features I guess. Yeah, yeah, yeah,  not   compensated .::	1
"mn007"::	Yeah, noisy - noisy features.::	0
"mn007"::	Um -::	0
"mn007"::	This is what we get after -::	0
"mn007"::	This - So, actually, we,  yeah,   here  the features are noise compensated and there is also the L_D_A filter.::	0
"mn007"::	Um, and then it's a pretty small neural network which use,::	0
"mn007"::	um,  nine frames of -::	0
"mn007"::	of six features from C_zero to C_fives, plus the first derivatives.::	0
"mn007"::	And it has one hundred hidden units.::	0
"me018"::	Is that nine frames u- s- uh, centered around the current frame? Or -::	0
"mn007"::	Yeah. Mm-hmm.::	0
"me013"::	S- so, I'm - I'm sorry, there's - there's - there's how many - how many inputs?::	0
"mn007"::	So it's twelve times nine.::	0
"me013"::	Twelve times nine inputs, and a hundred, uh, hidden.::	0
"mn007"::	Hidden and::	0
"mn052"::	Two outputs.::	0
"mn007"::	two outputs.::	0
"me013"::	Two outputs.::	0
"me013"::	O_K. So I guess about eleven thousand::	0
"me013"::	parameters,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	which - actually shouldn't be a problem, even in - in small phones. Yeah.::	0
"me018"::	So, I'm - I'm - s- so what is different between this and -::	0
"mn007"::	It should be O_K.::	0
"mn007"::	So the previous syst-  It's based on the system that has a fifty-three point sixty-six percent improvement.::	1
"me018"::	and what you -::	0
"mn007"::	It's the same system. The only::	1
"mn007"::	thing that changed is the n-::	0
"mn007"::	a p- eh - a es- the estimation of the silence probabilities.::	1
"me018"::	Ah. O_K.::	0
"mn007"::	Which now is based on, uh, cleaned features.::	1
"me013"::	And,  it's a l- it's a lot  better.::	1
"me018"::	Wow.::	0
"mn007"::	Yeah. Um -::	0
"me013"::	That's  great.::	0
"mn007"::	So it's - it's not  bad,  but the problem is still that the latency is too large.::	1
"me013"::	What's the latency?::	0
"mn007"::	Because -::	0
"mn007"::	um -::	0
"mn007"::	the - the latency of the V_A_D is two hundred and twenty milliseconds.::	1
"mn007"::	And, uh, the V_A_D is used::	0
"mn007"::	uh, i- for on-line normalization,::	0
"mn007"::	and it's used before the delta computation.::	0
"mn007"::	So if you add::	0
"mn007"::	these components it goes t- to a hundred and seventy, right?::	0
"me013"::	I - I'm confused. You started off with two-twenty and you ended up with one-seventy?::	0
"mn007"::	With two an- two hundred and seventy.::	0
"mn007"::	If - Yeah, if you add the c- delta comp- delta computation which is done afterwards.::	0
"me013"::	Two-seventy.::	0
"me013"::	Oh.::	0
"mn007"::	Um -::	0
"me013"::	So it's two-twenty. I- the- is this - are these twenty-millisecond::	0
"me013"::	frames? Is that why? Is it after downsampling? or -::	0
"mn007"::	The two-twenty is one hundred milliseconds for the um - No, it's forty milliseconds for t- for the, uh,::	0
"mn007"::	uh,::	0
"mn007"::	cleaning of the speech.::	0
"mn007"::	Um - then there is, um, the neural network which use::	0
"mn007"::	nine frames. So it adds forty milliseconds.::	0
"me013"::	a-::	0
"me013"::	O_K.::	0
"mn007"::	Um, after that, um, you have the um, filtering of the silence probabilities.::	0
"mn007"::	Which is a million  filter it ,::	0
"mn007"::	and it creates a one hundred milliseconds delay.::	0
"mn007"::	So, um -::	0
"me013"::	@@::	0
"mn052"::	Plus there is a delta at the input.::	0
"mn007"::	Yeah, and there is the delta at the input which is,::	0
"me013"::	One hundred::	0
"mn007"::	um -::	0
"me013"::	milliseconds for smoothing.::	0
"mn007"::	So it's -::	0
"me013"::	Uh, median.::	0
"mn007"::	@@  -::	0
"mn052"::	It's like forty plus - forty - plus -::	0
"mn007"::	Mmm. Forty -::	0
"me013"::	And then forty -::	0
"mn007"::	This forty plus twenty, plus one hundred.::	0
"me013"::	forty p-::	0
"me013"::	@@::	0
"mn052"::	So it's two hundred actually.::	0
"mn007"::	Uh -::	0
"mn007"::	Yeah, there are twenty that comes from -::	0
"mn007"::	There is ten that comes from the L_D_A filters also. Right?::	0
"mn052"::	Oh, O_K.::	0
"mn007"::	Uh, so it's::	0
"mn007"::	two hundred and ten, yeah.::	0
"mn052"::	If you are using -::	0
"me013"::	Uh -::	0
"mn007"::	Plus the frame, so it's two-twenty.::	0
"mn052"::	t- If you are using  three  frames - If you are phrasing f-  using  three  frames, it is thirty here for delta.::	0
"mn007"::	Yeah, I think it's - it's  five  frames, but.::	0
"mn052"::	So  five  frames, that's twenty.::	0
"mn052"::	O_K, so it's who un-  two hundred and ten.::	0
"me013"::	Uh, p- Wait a minute. It's forty -  forty for the - for the cleaning of the speech, forty for the I_N_ - A_N_N, a hundred for the smoothing.::	0
"mn007"::	So. Forty cleaning.::	0
"mn007"::	Yeah.::	0
"me013"::	Well, but at ten - ,::	0
"mn007"::	Twenty for the delta.::	0
"mn052"::	At th-  At the  input.  I mean, that's at the input to the net.::	0
"me013"::	Twenty for delta.::	0
"mn007"::	Yeah.::	0
"mn052"::	And there i-::	0
"me013"::	Delta at input to net?::	0
"mn007"::	Yeah.::	0
"mn052"::	Yeah.::	0
"mn052"::	So it's like s- five, six cepstrum plus delta at nine - nine frames of -::	0
"me013"::	And then ten milliseconds for -::	0
"mn052"::	Fi- There's an L_D_A filter.::	0
"me013"::	ten milliseconds for L_D_A filter,::	0
"me013"::	and t- and ten -  another  ten  milliseconds   you said for the frame?::	0
"mn007"::	For the frame I guess. I computed two-twenty - Yeah, well, it's -::	0
"mn007"::	I guess it's for the fr - the -::	0
"me013"::	O_K. And then there's delta  besides  that?::	0
"mn007"::	So this is the features that are used by our network and::	0
"mn007"::	then::	0
"mn007"::	afterwards,::	0
"mn007"::	you have to compute the delta on the, uh, main feature stream, which is::	0
"me013"::	O_K.::	0
"mn007"::	um, delta and double-deltas, which is fifty milliseconds.::	0
"me013"::	Yeah. No, I mean, the - after the noise part, the forty - the - the other hundred and eighty -::	0
"me013"::	Well, I mean,::	0
"me013"::	hhh,::	0
"me013"::	Wait a minute.  Some  of this is, uh - is, uh - is in  parallel,  isn't it? I mean, the L_D_A -::	0
"me013"::	Oh, you have the L_D_A as part of the V_D_- uh, V_A_D? Or -::	0
"mn007"::	The V_A_D use, uh, L_D_A filtered features also.::	0
"me013"::	Oh, it  does?::	0
"mn007"::	Mm-hmm.::	0
"me013"::	Ah.::	0
"me013"::	So in that case there isn't too much  in  parallel.::	0
"me013"::	Uh -::	0
"mn007"::	No. There is,::	0
"mn007"::	um,::	0
"mn007"::	just downsampling, upsampling,::	0
"mn007"::	and the L_D_A.::	0
"me013"::	Um, so the delta at the  end  is how much?::	0
"mn052"::	It's -::	0
"mn007"::	It's fifty.::	0
"me013"::	Fifty.::	0
"me013"::	Alright. So -::	0
"mn007"::	But well, we could probably put the delta, um,::	1
"mn007"::	before on-line normalization. It should not that make a big difference, because -::	1
"me018"::	What if you used a smaller window for the delta?::	1
"me018"::	Could  that  help a little bit?::	0
"me018"::	I mean, I guess there's a  lot  of things you could do to -::	1
"mn007"::	Yeah.::	0
"me013"::	Yeah.::	0
"mn007"::	Yeah, but, nnn -::	0
"me013"::	So- Yeah. So if you - if you put the delta before the, uh, ana- on-line - If - Yeah - uh - then - then it could go in parallel. And then y- then you don't have that additive -::	1
"mn007"::	Mm-hmm. Cuz i-::	0
"mn052"::	Yep.::	0
"mn007"::	Yeah, cuz the time constant of the on-line normalization is::	1
"mn007"::	pretty long compared to the::	0
"me013"::	O_K.::	0
"mn007"::	delta window, so.::	1
"mn007"::	It should not make -::	0
"me013"::	O_K.::	0
"me013"::	And you ought to be able to shove  tw- , uh - sh- uh - pull off twenty milliseconds from  somewhere  else to get it under two hundred, right? I mean -::	0
"mn007"::	Mm-hmm.::	0
"me018"::	Is two hundred the d-::	0
"me013"::	The hundred milla-::	0
"me013"::	mill- a hundred milliseconds for smoothing is sort of an arbitrary amount. It could be eighty and - and probably do  @@  -::	0
"mn007"::	Yeah, yeah.::	0
"me018"::	i- a hun- uh - Wh- what's the baseline you need to be under?::	1
"me013"::	Well, we don't know. They're still arguing about it.  I mean, if it's two - if - if it's, uh -::	1
"me018"::	Two hundred?::	0
"mn007"::	@@::	0
"me018"::	Oh.::	0
"me013"::	if it's two-fifty,::	0
"me013"::	then we could keep the delta where it is if we shaved off twenty. If it's two hundred,::	1
"me013"::	if we shaved off twenty, we could - we could, uh, meet it by moving the delta back.::	1
"me018"::	So, how do you know that what you have is too  much  if they're still deciding?::	1
"me013"::	Uh, we don't, but it's just - I mean, the  main  thing is that since that we got burned last time,::	1
"me013"::	and - you know, by not worrying about it very much, we're just staying  conscious  of it.::	1
"me018"::	Uh-huh.::	0
"me018"::	Oh, O_K, I see.::	0
"me013"::	And so, th- I mean, if - if - if a week before we have to be done someone says, "Well, you have to have fifty milliseconds less than you have now", it  would  be pretty frantic around here. So -::	1
"me018"::	Ah, O_K.::	0
"me013"::	Uh -::	0
"me018"::	But  still,  that's - that's a pretty big, uh,  win.  And it doesn't seem like you're - in terms of your::	0
"me018"::	delay,  you're, uh, that -::	0
"me013"::	He added a bit on, I  guess,  because  before  we were - we were - had - were able to have the noise,::	0
"mn007"::	Hmm.::	0
"me013"::	uh, stuff, uh, and the L_V_A be in  parallel.  And now he's - he's requiring it to be done first.::	0
"mn007"::	Well, but- I think the main thing, maybe, is the cleaning of the speech, which takes forty milliseconds or so.::	0
"mn007"::	And -::	0
"me013"::	Right. Well, so you say - let's say ten  milliseconds   - seconds for the L_D_A.::	0
"mn007"::	and - but - the L_D_A is, well, pretty  short  right now. Yeah.::	0
"me013"::	Well, ten.::	0
"me013"::	And then forty for the other.::	0
"mn052"::	Yeah, the L_D_A - L_D_A - we don't know, is, like - is it very crucial for the features, right?::	0
"mn007"::	No. I just -::	0
"mn007"::	This is the first try. I mean, I - maybe the L_D_A's not very useful then.::	0
"mn052"::	Yeah.::	0
"mn052"::	S- s- h-::	0
"me013"::	Right, so you could start pulling back, but -::	0
"mn052"::	Yeah, l-::	0
"me013"::	But I think you have - I mean, you have twenty for delta computation which y- now you're sort of doing twice, right? But yo- w- were you doing that before?::	0
"mn007"::	Mmm.::	0
"mn052"::	On the - in the - Mm-hmm.::	0
"mn007"::	Well, in the proposal, um, the input of the V_A_D network were::	0
"mn052"::	Just -::	0
"mn007"::	just three frames, I think.::	0
"mn052"::	Yeah, just the static, no delta.::	0
"mn007"::	Uh, static features.::	0
"me013"::	Right.::	0
"me013"::	So, what you have now is fort- uh, forty for the - the noise, twenty for the delta, and ten for the L_D_A. That's seventy milliseconds::	0
"mn007"::	@@::	0
"me013"::	of stuff which was formerly in parallel, right?::	0
"me013"::	So I think,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	you know, that's - that's the difference as far as the  timing,  right?::	0
"mn007"::	Yeah.::	0
"me013"::	Um, and you could experiment with cutting various pieces of these back a bit, but -::	1
"me013"::	I mean, we're s- we're not -::	1
"me013"::	we're not in terrible shape.::	1
"me018"::	Yeah, that's what it seems like to me. It's pretty good.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	Yeah. It's - it's not like it's adding up to four hundred milliseconds or something.::	0
"me018"::	Where - where is this -::	1
"me018"::	where is this fifty-seven point O_ two in - in comparison to the last evaluation?::	1
"me013"::	Well, it's - I think it's better than anything, uh, anybody got.::	1
"mn007"::	Yeah.::	0
"me018"::	Oh, is that right?::	0
"mn007"::	The best was fifty-four::	1
"me013"::	Yeah.::	0
"mn007"::	point five.::	1
"mn052"::	Point s-::	0
"me018"::	Oh.::	0
"me013"::	Yeah. Uh-::	0
"mn007"::	And our system was::	0
"mn007"::	forty-nine, but with the neural network.::	0
"me018"::	Wow. So  this  is almost ten  percent.::	0
"me013"::	With the f-  with  the neural net. Yeah, and r- and -::	0
"mn052"::	Yeah, so this is - this is like the  first  proposal. The proposal- one.  It was forty-four, actually.::	0
"mn007"::	It would-::	0
"me013"::	Yeah. Yeah. And we still don't have the neural net in. So - so it's - You know. So it's -::	0
"me018"::	Wow.::	0
"me013"::	We're - we're doing  better.  I mean, we're getting::	0
"me018"::	This is - this is really good.::	0
"me013"::	better  recognition.  I mean, I'm sure other people working on this are not sitting still  either,  but -::	0
"me013"::	but -::	0
"me018"::	Yeah.::	0
"me013"::	but, uh -::	0
"me013"::	Uh, I mean, the  important  thing is that we::	0
"me013"::	learn how to do this better, and,::	0
"me013"::	you know. So.::	0
"me013"::	Um,::	0
"me013"::	Yeah.  So, our,::	0
"me013"::	um -::	0
"me013"::	Yeah, you can see the kind of - kind of numbers that we're having, say, on SpeechDat-Car which is a hard task, cuz::	0
"me013"::	it's really, um - I  think  it's just sort of -::	0
"me013"::	sort of reasonable numbers,::	0
"me013"::	starting   to be.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	I mean, it's still  terri-::	0
"mn007"::	Yeah, even for a well-matched case it's::	0
"mn007"::	sixty percent error rate reduction, which is -::	0
"me013"::	Yeah.::	0
"me013"::	Yeah.  Probably half.::	0
"me013"::	Good!::	0
"mn007"::	Um,::	0
"mn007"::	Yeah.::	0
"mn007"::	So actually, this is in between::	0
"mn007"::	what we had with the previous V_A_D and::	0
"mn007"::	what Sunil did with an I_D_L V_A_D.::	0
"mn007"::	Which gave sixty-two percent improvement, right?::	0
"mn052"::	Yeah, it's almost that. It's almost an average somewhere around - Yeah.::	0
"mn007"::	So -::	0
"mn007"::	Yeah.::	0
"me018"::	What was that? Say that last part again?::	0
"mn007"::	So, if you use, like, an I_D_L V_A_D,::	0
"mn052"::	o- o-::	0
"mn007"::	uh, for dropping the frames,::	0
"mn052"::	Or the best we can get.::	0
"mn007"::	the best that we can get - i- That means that we estimate the silence probability on the clean version of the utterances.::	0
"mn007"::	Then you can go up to sixty-two percent error rate reduction, globally.::	0
"me018"::	Mmm.::	0
"mn007"::	Mmm -::	0
"mn007"::	Yeah.::	0
"me018"::	So that would be even - That wouldn't change this number down here to  sixty-two?::	0
"mn007"::	Yeah.::	0
"me013"::	Yeah. So you - you were get-::	0
"mn007"::	If you add a g- good v-  very  good V_A_D,::	0
"me018"::	Yeah.::	0
"mn007"::	that works as well as a V_A_D working on clean speech,::	0
"me018"::	Yeah.::	0
"mn007"::	then you wou- you would go -::	0
"me018"::	So that's sort of the best you could hope for.::	0
"mn007"::	Mm-hmm.::	0
"me018"::	I see.::	0
"me013"::	Probably.  Yeah.::	0
"me013"::	So fi- si- fifty-three is what you were getting with the old V_A_D.::	0
"mn007"::	Yeah.::	0
"me013"::	And, uh -::	0
"me013"::	and sixty-two with the - the, you know, quote, unquote, cheating V_A_D. And fifty-seven is what you got with the real V_A_D.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	That's great.::	0
"mn007"::	Uh, yeah, the next thing is, I started to play -::	0
"mn007"::	Well, I don't want to worry too much about the delay, no. Maybe it's better to wait::	0
"me013"::	O_K.::	0
"mn007"::	for the decision::	0
"me013"::	Yeah.::	0
"mn007"::	from the committee.::	0
"mn007"::	Uh, but I started to play with the, um,::	1
"mn007"::	uh, tandem neural network.::	1
"mn007"::	Mmm::	0
"mn007"::	I just did the configuration that's very similar to::	1
"mn007"::	what we did for the February proposal.::	1
"mn007"::	And -::	0
"mn007"::	Um. So. There is a f- a first feature stream that use uh straight::	1
"mn007"::	M_F_C_C features.::	1
"me013"::	Mm-hmm.::	0
"mn007"::	Well, these features actually.::	0
"mn007"::	And the other stream is the output of a neural network, using as input, also, these,::	1
"mn007"::	um,::	0
"mn007"::	cleaned::	0
"mn007"::	M_F_C_C.::	1
"mn007"::	Um -::	0
"mn007"::	I don't have the comp- Mmm?::	0
"me018"::	Those are th- those are th- what is going into the tandem net?::	0
"me018"::	Those two?::	0
"mn007"::	So there is just  this  feature stream,  the fifteen M_F_C_C plus delta and double-delta.::	0
"me013"::	No.::	0
"me018"::	Yeah?::	0
"mn007"::	Um, so it's - makes forty-five features  that are used as input to the H_T_K.::	0
"mn007"::	And then, there is - there are more inputs that comes from the tandem M_L_P.::	0
"me018"::	Oh, oh. O_K. I see.::	0
"me013"::	Yeah, h- he likes to use them  both,  cuz then it has one part that's discriminative, one part that's not.::	0
"me018"::	Uh- huh.::	0
"mn007"::	Yeah. Um -::	0
"me018"::	Right. O_K.::	0
"mn007"::	So, um,::	0
"mn007"::	uh, yeah. Right now it seems::	0
"mn007"::	that - i- I just tested on SpeechDat-Car while the experiment are running on  your  - on T_I-digits.::	0
"mn007"::	Well, it improves on the well-matched and the mismatched conditions, but it::	1
"mn007"::	get worse on the highly mismatched.::	1
"mn007"::	Um,::	0
"me018"::	Compared to  these  numbers?::	0
"mn007"::	Compared to these numbers, yeah.::	0
"mn007"::	Um, like, on the well-match and medium mismatch, the gain is around five percent relative,::	0
"me013"::	y-::	0
"mn007"::	but it goes down::	0
"mn007"::	a lot more, like::	0
"mn007"::	fifteen percent on the H_M case.::	0
"me013"::	You're just using the full ninety features?::	1
"mn007"::	@@::	0
"mn007"::	The -::	0
"me013"::	Y- you have ninety features?::	0
"mn007"::	i-::	0
"mn007"::	I have, um -::	0
"mn007"::	From the networks, it's twenty-eight. So -::	1
"me013"::	And from the other side it's forty-five. So it's - you have seventy-three features,::	1
"mn007"::	So, d- i- It's forty-five. Yeah.::	0
"mn007"::	Yeah.::	0
"me013"::	and you're just feeding them like that.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	There isn't any K_L_T or anything?::	0
"mn007"::	There's a K_L_T after the neural network, as - as before.::	1
"me018"::	That's how you get down to twenty-eight?::	1
"mn007"::	Yeah.::	0
"me018"::	Why twenty-eight?::	0
"mn007"::	I don't know.  Uh.   It's -::	0
"me018"::	Oh.::	0
"mn007"::	i- i- i- It's because it's what we did for the first proposal. We tested,::	0
"me018"::	Ah.::	0
"mn007"::	uh, trying to go down  and   Yeah.::	0
"me013"::	It's a multiple of seven.::	0
"mn052"::	Yeah.   Yeah. Yeah.::	0
"mn007"::	So -::	0
"mn007"::	Um.::	0
"mn007"::	I wanted to do something very similar to the proposal as a first -::	1
"me018"::	I see.::	0
"me013"::	Yeah.::	0
"me018"::	Yeah. That makes sense.::	0
"mn007"::	first try.::	1
"mn007"::	But we have to - for sure, we have to go down, because the limit is now sixty features. So,::	1
"me013"::	Yeah.::	0
"mn007"::	uh, we have to find a way to decrease::	1
"mn007"::	the number of features.::	1
"mn007"::	Um -::	0
"me018"::	So, it seems funny that -::	0
"me018"::	I don't know, maybe I don't u- quite understand everything,  but that adding features -::	0
"me018"::	I guess - I guess if you're keeping the  back-end   fixed.::	0
"me018"::	Maybe  that's  it. Because it seems like just adding information shouldn't give worse results. But I guess if you're::	0
"me018"::	keeping the number of Gaussians fixed in the  recognizer,  then -::	0
"me013"::	Well, yeah. But, I mean, just in general, adding information -::	0
"mn007"::	Mmm.::	0
"me013"::	Suppose the information you added,  well , was a really terrible feature and all it brought in was  noise.::	0
"me018"::	Yeah.::	0
"me013"::	Right? So - so, um -::	0
"me013"::	Or - or suppose it wasn't::	0
"me013"::	completely  terrible,  but it was  completely   equivalent  to  another  one feature that you had,::	0
"me013"::	except it was  noisier.::	0
"me018"::	Uh-huh.::	0
"me013"::	Right? In that case you wouldn't necessarily expect it to be better at  all.::	0
"me018"::	Oh, yeah, I wasn't necessarily saying it should be  better.::	0
"me018"::	I'm just surprised that you're getting fifteen percent relative  worse::	0
"me013"::	Uh-huh.::	0
"mn007"::	But it's worse.::	0
"me018"::	on the wel- On the highly mismatch. Yeah.::	0
"me013"::	On the highly mismatched condition.::	0
"mn007"::	Yeah, I -::	0
"me013"::	So, "highly mismatched condition" means that in fact your training is a bad estimate of your test.::	0
"mn007"::	Uh-huh.::	0
"me013"::	So having - having, uh, a g- a l- a greater number of  features,  if they aren't maybe the right features that you use, certainly can e- can  easily,::	0
"me013"::	uh, make things worse.::	0
"me013"::	I mean, you're  right.  If you have - if you have, uh, lots and lots of data,::	0
"me013"::	and you have - and your - your - your training is representative of your test,::	0
"me013"::	then getting more sources of information should just help. But - but it's -::	0
"me013"::	It doesn't necessarily work that way.::	0
"me018"::	Huh.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	So I wonder, um,::	0
"me013"::	Well, what's your - what's your thought about what to do next with it?::	1
"mn007"::	Um, I don't know. I'm surprised, because::	1
"mn007"::	I expected the neural net to help more::	0
"mn007"::	when there is more mismatch, as::	0
"mn007"::	it was the case for the -::	1
"mn052"::	So, was the training set same as the p- the February proposal?::	0
"me013"::	Mm-hmm.::	1
"mn052"::	@@::	0
"mn007"::	Yeah, it's the same training set, so it's TIMIT with::	0
"mn052"::	O_K.::	0
"mn007"::	the T_I-digits', uh, noises,::	0
"me013"::	Mm-hmm.::	0
"mn007"::	uh, added.::	0
"mn007"::	Um -::	0
"me013"::	Well, we might - uh, we might have to experiment with, uh::	1
"me013"::	better training sets. Again. But, I - The  other  thing is, I mean,  before  you found that was the best configuration, but you might have to retest those things now that we have different -::	1
"mn007"::	Mm-hmm.::	0
"me013"::	The rest of it is different, right? So, um,::	1
"me013"::	uh,::	0
"me013"::	For instance, what's the effect of just putting::	1
"me013"::	the neural net on without the o- other - other path?::	1
"mn007"::	Mm-hmm.::	0
"mn007"::	Yeah.::	0
"me013"::	I mean, you know what the  straight  features do. That gives you  this.::	1
"mn007"::	Mm-hmm.::	0
"me013"::	You know what it does in  combination.::	0
"me013"::	You don't necessarily know what -::	0
"me018"::	What if you did the -  Would it make sense to do the K_L_T::	0
"me018"::	on the full set of  combined  features?::	0
"me018"::	Instead of just on the -::	0
"mn007"::	Yeah. I g- I  guess.  Um. The reason I did it this ways is that::	0
"mn007"::	in February, it - we - we tested different things like that,::	0
"mn007"::	so, having two K_L_T, having just a K_L_T for a network,::	0
"mn007"::	or having a global K_L_T.::	0
"me018"::	Oh, I see.::	0
"mn007"::	And -::	0
"me018"::	So you  tried  the global K_L_T before and it didn't really -::	0
"mn007"::	Well -::	0
"mn007"::	Yeah. And, uh, th- Yeah. The differences between these configurations were not huge, but -::	0
"me018"::	I see.::	0
"mn007"::	it was::	0
"mn007"::	marginally better with::	0
"mn007"::	this configuration.::	0
"me018"::	Uh-huh. Uh-huh.::	0
"me013"::	But, yeah, that's obviously another thing to try,::	0
"mn007"::	Um.::	0
"me013"::	since things are - things are different. And I guess if the -::	0
"mn007"::	Mm-hmm. Mm-hmm.::	0
"me013"::	These are all - so all of these seventy-three features are going into,::	0
"me013"::	um,::	0
"me013"::	the, uh - the H_M_M.::	0
"mn007"::	Yeah.::	0
"me013"::	And is - are - i- i- are - are any deltas being computed of tha- of  them?::	0
"mn007"::	Of the straight features, yeah.::	0
"mn007"::	So.::	0
"me013"::	n- Not of the -::	0
"mn007"::	But n- th- the, um,::	0
"mn007"::	tandem features are::	0
"mn007"::	u-::	0
"me013"::	Are not.::	0
"mn007"::	used as they are. So,::	0
"mn007"::	yeah, maybe we can add some context from these features also as -::	0
"me013"::	Could.  i-::	0
"mn007"::	Dan did in - in his last work.::	0
"me013"::	Yeah, but the other thing I was thinking was, um -::	0
"me013"::	Uh, now I lost track of what I was thinking. But.::	0
"me018"::	What is the -::	0
"me018"::	You said there was a limit of sixty features or something?::	0
"mn007"::	Mm-hmm.::	0
"me018"::	What's the relation between that limit and the, um, forty-eight -::	0
"me013"::	Oh, I know what I was gonna say.::	0
"me018"::	uh, forty eight hundred::	0
"me018"::	bits per second?::	0
"mn007"::	Um, not - no relation. The f- the forty-eight::	0
"me013"::	No relation.::	0
"me018"::	So I - I - I don't understand, because i-::	0
"mn007"::	hundred bits is for transmission of some features.::	0
"me018"::	I mean, if you're only using h-::	0
"mn007"::	And generally, i- it - s- allows you to transmit like, fifteen,::	0
"mn007"::	uh, cepstrum.::	0
"me013"::	The  issue  was that, um, this is supposed to be a standard that's then gonna be fed to somebody's recognizer somewhere::	0
"me013"::	which might be, you know, it - it might be a concern how many parameters are use - u- used and so forth. And so,::	0
"me013"::	uh, they felt they wanted to set a limit.::	1
"me013"::	So they chose sixty.::	1
"me013"::	Some people wanted to use hundreds of parameters and - and that bothered some other people. u- And so::	0
"me018"::	Uh-huh.::	0
"me013"::	they just chose that. I - I - I think it's kind of r- arbitrary too. But -::	1
"me013"::	but that's - that's kind of what was chosen. I - I remembered what I was going to say. What I was going to say is that, um,::	0
"me013"::	maybe  -  maybe with the noise removal, uh, these things are now more correlated.::	0
"me013"::	So you have two sets of things that are kind of uncorrelated, uh,::	0
"me013"::	within  themselves,::	0
"me013"::	but they're pretty correlated with one  another.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	And, um,::	0
"me013"::	they're being fed into these, uh, variants, only Gaussians and so forth, and - and, uh,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	so maybe it would be::	0
"me013"::	a better idea now than it was before to, uh, have, uh, one K_L_T over everything,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	to de-correlate it.::	0
"mn007"::	Yeah, I see.::	0
"me013"::	Maybe.   You know .::	0
"mn052"::	What are the S_N_Rs in the training set, TIMIT?::	0
"mn007"::	It's, uh, ranging from::	0
"mn007"::	zero to clean?::	0
"mn052"::	Mm-hmm.::	0
"mn007"::	Yeah. From zero to clean.::	0
"me013"::	Yeah.::	0
"me013"::	So we found this - this, uh - this Macrophone data,::	0
"me013"::	and so forth, that we were using for these other experiments, to be pretty good. So that's - i- after you explore these other alternatives, that might be another way to start looking, is - is just improving the training set.::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	I mean, we were getting,::	0
"me013"::	uh,  lots::	0
"me013"::	better::	0
"me013"::	recognition::	0
"me013"::	using that, than -::	0
"me013"::	Of course, you  do  have the problem that,::	0
"me013"::	um,::	0
"me013"::	u- i-::	0
"me013"::	we are not able to increase the number of Gaussians, uh, or anything to, uh,::	0
"me013"::	uh,::	0
"me013"::	to  match  anything. So we're only improving the training of our feature set, but that's still probably something.::	0
"me018"::	So you're saying, add the Macrophone data to the training of the neural net? The tandem net?::	0
"me013"::	Yeah, that's the only place that we can  train.  We can't train the other stuff with anything other than the standard amount, so.::	0
"me018"::	Yeah.::	0
"me018"::	Right.::	0
"me013"::	Um,::	0
"me013"::	um -::	0
"me018"::	What -  what  was it trained on again? The one that you used?::	0
"mn007"::	It's TIMIT with noise.::	0
"me018"::	Uh-huh.::	0
"mn007"::	So, yeah, it's rather a small -::	0
"me013"::	Yeah.::	0
"me013"::	How  big  is the  net,  by the way?::	0
"mn007"::	Um,::	0
"mn007"::	Uh, it's, uh, five hundred hidden units. And -::	0
"me013"::	And again, you did experiments back then where you made it bigger and it - and that was - that was sort of the::	0
"me013"::	threshold point. Much less than that, it was worse, and::	0
"mn007"::	Yeah.::	0
"mn007"::	Yeah.::	0
"me013"::	much more than that, it wasn't much better.::	0
"me013"::	Hmm.::	0
"mn052"::	So is it - is it  though  the performance,::	0
"mn007"::	Yeah.  @@ ?::	0
"mn052"::	big relation in the high ma- high mismatch has something to do with the,::	0
"mn052"::	uh, cleaning up::	0
"mn052"::	that you - that is done on the TIMIT after adding noise? So -::	0
"mn052"::	it's - i- All the noises are from the T_I-digits, right?::	0
"mn007"::	Yeah.::	0
"mn052"::	So you - i-::	0
"mn007"::	Um -::	0
"mn052"::	Well, it- it's like the high mismatch of the SpeechDat-Car::	0
"mn007"::	They - k- uh -::	0
"mn052"::	after cleaning up, maybe having more noise than the -::	0
"mn052"::	the training set of TIMIT after clean - s- after you do the noise clean-up.::	0
"mn007"::	Mmm.::	0
"mn052"::	I mean,  earlier  you never  had  any compensation, you just trained it straight away.::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	So it had like all these different conditions of S_N_Rs,::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	actually in their training set of neural net.::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	But after cleaning up you have now a different set of S_N_Rs, right?::	0
"mn052"::	For the training of the neural net.::	0
"mn007"::	Yeah.::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	And -::	0
"mn052"::	is it something to do with the mismatch that - that's created  after  the cleaning up, like the high mismatch -::	0
"mn007"::	You mean the - the most noisy::	0
"mn007"::	occurrences on SpeechDat-Car might be::	0
"mn052"::	Mm-hmm.::	0
"mn007"::	a lot more noisy than -::	0
"mn052"::	Of - that - I mean, the S_N_R after the noise compensation of the SpeechDat-Car.::	0
"me013"::	Oh, so - Right. So the training - the - the  neural net   is being trained with noise compensated::	0
"mn007"::	Maybe.::	0
"mn052"::	@@::	0
"mn052"::	Yeah.::	0
"mn007"::	Yeah, yeah.::	0
"me013"::	stuff. Which makes  sense,::	0
"mn052"::	Yeah.::	0
"me013"::	but, uh, you're saying - Yeah, the noisier::	0
"me013"::	ones are  still  going to be,::	0
"mn052"::	Yeah.::	0
"me013"::	even after our noise compensation, are still gonna be pretty noisy.::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	Yeah, so now the after-noise  compensation  the neural net is seeing a different set of S_N_Rs than that was originally there in the training set.::	0
"mn052"::	Of TIMIT. Because in the TIMIT it was zero to some clean.::	0
"me013"::	Right.::	0
"mn052"::	So the net saw all the S_N_R  @@::	0
"me013"::	Yes.::	0
"mn052"::	conditions. Now after cleaning up it's a different set of S_N_R.::	0
"me013"::	Right.::	0
"me013"::	Right.::	0
"mn052"::	And that S_N_R may not be, like, com- covering the whole set of S_N_Rs that you're getting in the SpeechDat-Car.::	0
"me013"::	Right, but the SpeechDat-Car data that you're seeing is  also  reduced in noise by the  noise  compensation.::	0
"mn052"::	Yeah, yeah, yeah, yeah, it  is.  But, I'm saying, there could be some -::	0
"mn007"::	Yeah.::	0
"me013"::	So.::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	some issues of -::	0
"me013"::	Yeah.::	0
"mn007"::	Well, if the initial range of S_N_R is different, we - the problem was already there before. And -::	0
"me013"::	Yeah.::	0
"mn007"::	Because -::	0
"mn007"::	Mmm -::	0
"me013"::	Yeah, I mean, it depends on whether you believe that the noise compensation is equally reducing the noise on the test set and the training set.  Uh -::	0
"mn007"::	Hmm.::	0
"mn052"::	On the test set, yeah.  @@::	0
"me013"::	Right? I mean, you're saying there's a mismatch in  noise::	0
"mn052"::	Hmm.::	0
"mn052"::	Mm-hmm.::	0
"me013"::	that wasn't there  before,  but if they were both the  same  before, then if they were both reduic- reduced  equally,::	0
"mn052"::	Mm-hmm.::	0
"me013"::	then,::	0
"me013"::	there would  not  be a mismatch.::	0
"me013"::	So, I mean, this may be -::	0
"me013"::	Heaven forbid, this::	0
"me013"::	noise compensation process may be  imperfect,::	0
"me013"::	but.  Uh, so maybe it's treating some things differently.::	0
"mn052"::	Well, I -::	0
"mn007"::	Yeah, uh -::	0
"mn052"::	I don't know. I - I just - that could be seen from the T_I-digits, uh, testing condition because, um, the noises are from the T_I-digits, right? Noise -::	0
"mn007"::	Yeah. So -::	0
"mn052"::	So cleaning up the T_I-digits and if the performance::	0
"mn052"::	goes  down   in  the T_I-digits mismatch -  high  mismatch like this -::	0
"mn007"::	Clean training, yeah.::	0
"mn052"::	on a clean training, or zero D_B testing.::	0
"mn007"::	Yeah, we'll - so we'll see. Uh. Maybe.::	0
"mn052"::	Yeah. Then it's something to do.::	0
"mn007"::	Mm-hmm.  Yeah.::	0
"me013"::	I mean, one of the things about - I mean, the Macrophone data,::	0
"me013"::	um, I think, you know, it was recorded over many different telephones.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	And, um, so, there's lots of different kinds of acoustic conditions.::	0
"me013"::	I mean, it's not artificially added noise or anything.::	0
"me013"::	So it's not the same. I don't think there's  anybody  recording over a car::	0
"me013"::	from a car, but - I think it's - it's varied enough that if - if doing this adjustments, uh, and playing around with it::	0
"me013"::	doesn't, uh, make it better, the most - uh, it seems like the most obvious thing to do is to improve the training set.::	0
"me013"::	Um - I mean, what we were -::	0
"me013"::	uh - the condition - It - it gave us an  enormous  amount of improvement in what we were doing with  Meeting  Recorder digits, even though::	0
"me013"::	there,  again,  these m- Macrophone::	0
"me013"::	digits were very, very  different  from, uh,::	0
"me013"::	what we were going on  here.  I mean, we weren't talking over a telephone here.::	0
"me013"::	But it was just - I think just having a - a nice variation in::	0
"me013"::	acoustic conditions was just a good thing.::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	Mmm.::	0
"mn007"::	Yep.::	0
"mn007"::	Yeah, actually  to s- eh, what I observed in the H_M::	1
"mn007"::	case is that::	0
"mn007"::	the number of deletion::	0
"mn007"::	dramatically increases. It -::	1
"mn007"::	it doubles.::	1
"me013"::	Number of   deletions.::	0
"mn007"::	When I added the num- the neural network it doubles the number of deletions.::	1
"mn007"::	Yeah, so I don't you know::	1
"mn007"::	how to interpret that, but, mmm -::	1
"me013"::	Yeah. Me  either.::	1
"mn007"::	t-::	0
"me018"::	And - and did - an- other numbers stay the same? Insertion substitutions stay the same?::	1
"mn007"::	They p- stayed the same, they - maybe they are a little bit::	1
"me018"::	Roughly?::	0
"mn007"::	uh, lower.::	0
"me018"::	Uh-huh.::	0
"mn007"::	They are a little bit better. Yeah. But -::	0
"mn007"::	Mm-hmm.::	0
"me013"::	Did they increase the number of deletions even for the::	1
"me013"::	cases that got  better?  Say, for the - I mean, it - So it's only the highly mismatched?::	1
"mn007"::	No, it doesn't. No.::	1
"me013"::	And it - Remind me again, the "highly mismatched" means that the -::	0
"mn007"::	Clean training and -::	0
"me013"::	Uh, sorry?::	0
"mn007"::	It's clean training - Well, close microphone training and::	0
"me013"::	Close mike training -::	0
"mn007"::	distant microphone, um, high speed, I think. Well -::	0
"mn007"::	The most noisy cases are the distant microphone for testing.::	0
"me013"::	Right.::	0
"me013"::	So -::	0
"me013"::	Well, maybe the noise subtraction is::	0
"me013"::	subtracting off  speech.   Wh-::	0
"mn007"::	Separating .::	0
"mn007"::	Yeah.::	0
"mn007"::	But - Yeah.::	0
"mn007"::	I mean, but without the neural network it's - well, it's better. It's just when we add the neural networks. The feature are the same except that -::	0
"me013"::	Yeah, right. Uh, that's right, that's right. Um -::	0
"me018"::	Well that - that says that, you know, the, um -::	0
"me018"::	the models in - in, uh,::	0
"me018"::	the recognizer are really paying attention to the neural net features.::	0
"mn007"::	Yeah.  Mm-hmm.::	0
"me018"::	Uh.::	0
"me013"::	But, yeah,  actually  -::	0
"me013"::	the TIMIT noises  are sort of a range of noises and they're not so much the stationary::	0
"me013"::	driving kind of noises, right? It's - it's pretty different. Isn't it?::	0
"mn007"::	Uh, there  is  a car noise. So there are f- just four noises. Um,::	0
"mn007"::	uh, "Car", I think,::	0
"mn052"::	"Babble."::	0
"mn007"::	"Babble", "Subway", right? and -::	0
"mn052"::	"Street" or "Airport" or something.::	0
"mn007"::	and - "Street" isn't - " Train  station", yeah.::	0
"mn052"::	Or "Train station".::	0
"mn052"::	Yeah.::	0
"mn007"::	So - it's mostly - Well, "Car" is stationary,::	0
"me013"::	Mm-hmm.::	0
"mn007"::	"Babble",::	0
"mn007"::	it's a stationary background plus some voices,::	0
"me013"::	Mm-hmm.::	0
"mn007"::	some speech::	0
"mn007"::	over it. And::	0
"mn007"::	the other two are rather stationary also.::	0
"me013"::	Well, I - I think that::	0
"me013"::	if you run it -::	0
"me013"::	Actually, you - maybe you remember this. When you - in - in the  old  experiments when you ran::	1
"me013"::	with the neural net only, and didn't have this side path,::	0
"me013"::	um, uh, with the - the pure features as well,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	did it::	0
"me013"::	make things  better  to have the neural net? Was it about the  same?::	1
"me013"::	Uh, w- i-::	0
"mn007"::	It was -::	1
"mn007"::	b- a little bit worse.::	1
"me013"::	Than - ?::	0
"mn007"::	Than just the features, yeah.::	0
"me013"::	So,::	0
"me013"::	until you put the second path in with the pure features, the neural net wasn't helping at all.::	1
"mn007"::	Mm-hmm.::	0
"me013"::	Well,  that's  interesting.::	0
"mn007"::	It was helping,::	1
"mn007"::	uh, if the features are b-::	0
"mn007"::	were bad, I mean.::	1
"me013"::	Yeah.::	0
"mn007"::	Just plain P_L_Ps or M_F_C_Cs.::	0
"me013"::	Yeah.::	0
"mn007"::	But::	1
"mn007"::	as soon as we added L_D_A on-line normalization, and::	0
"mn007"::	all these things, then -::	1
"me013"::	They were doing similar enough things.::	1
"me013"::	Well, I  still  think it would be k- sort of interesting to see::	0
"me013"::	what::	0
"me013"::	would happen if you just had the neural net without the side thing. And - and the thing I - I have in mind is,::	1
"mn007"::	Yeah, mm-hmm.::	0
"me013"::	uh,  maybe  you'll see that the results are  not  just a little bit worse. Maybe that::	1
"me013"::	they're a  lot  worse.::	1
"me013"::	You know? And, um -::	0
"me013"::	But if on the ha- other hand,::	1
"me013"::	uh, it's, say, somewhere in  between  what you're seeing now and - and - and, uh, what you'd have with just the pure features,::	0
"me013"::	then maybe there  is  some problem of a -::	0
"me013"::	of a, uh, combination::	0
"me013"::	of these things, or correlation between them somehow.::	1
"mn007"::	Mm-hmm.::	0
"me013"::	If it really is that the  net  is  hurting  you at the moment, then::	1
"me013"::	I think the issue is to::	0
"me013"::	focus on - on, uh, improving the - the  net.::	1
"mn007"::	Yeah, mm-hmm.::	0
"me013"::	Um.::	0
"me013"::	So what's the overall effe- I mean, you haven't done all the experiments but you said::	0
"me013"::	it was i-::	0
"me013"::	somewhat better, say, five percent better, for the first two conditions, and fifteen percent worse for the  other  one?::	0
"me013"::	But it's - but of course that one's  weighted  lower, so I wonder what the net  effect  is.::	0
"mn007"::	Y- yeah, oh. Yeah.::	0
"mn007"::	I d- I -::	0
"mn007"::	I think it's - it was one or two percent.::	0
"mn007"::	That's not that bad, but it was l- like two percent::	0
"mn007"::	relative worse on SpeechDat-Car.::	0
"mn007"::	I have to - to check that. Well, I have - I will.::	0
"mn052"::	Well, it will -  overall  it will be still better even if it is fifteen percent worse,::	0
"mn052"::	because the fifteen percent::	0
"mn052"::	worse is given like f- w- twenty-five -::	0
"me013"::	Right.::	0
"mn052"::	point two five eight.::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Hmm.::	0
"me013"::	Right. So the - so the worst it could be, if the others were  exactly  the same, is  four,::	0
"mn052"::	Is it like -::	0
"mn052"::	Yeah, so it's four.::	0
"me013"::	and - and, uh, in fact since the others are somewhat better -::	0
"mn052"::	Is i-::	0
"mn052"::	So either it'll get cancelled out, or you'll get, like, almost the same.::	0
"mn007"::	Yeah, it was - it was slightly worse. Um,::	0
"me013"::	Uh.::	0
"mn052"::	Slightly bad.::	0
"mn052"::	Yeah.::	0
"me013"::	Yeah, it should be pretty close to cancelled out.::	0
"mn052"::	Yeah.::	0
"mn007"::	Mm-hmm.::	0
"me018"::	You know,  I've  been wondering about something. In the, um - a lot of the, um -::	1
"me018"::	the Hub-five systems, um, recently have been using L_D_A.::	1
"me018"::	and - and they, um -::	1
"me018"::	They run L_D_A on the features right before they train the models.::	1
"me018"::	So there's the - the L_D_A is - is right there before the H_M_Ms.::	0
"mn052"::	Yeah.::	0
"me018"::	So, you guys are using L_D_A but it seems like it's pretty far back in the process.::	0
"mn052"::	Uh, this L_D_A is different from the L_D_A that you are talking about. The L_D_A that you -::	1
"mn052"::	saying is, like, you take a block of features, like nine frames or something,::	0
"me018"::	Yeah.::	0
"me018"::	Uh-huh.::	0
"mn052"::	and then do an L_D_A on it, and then reduce the dimensionality to something like twenty-four or something like that.::	1
"mn052"::	And then feed it to H_M_M.::	0
"me018"::	Yeah, you c- you c- you  can.  I mean, it's - you know, you're just basically i-::	0
"mn052"::	Yeah, so this is like a two d-::	0
"mn052"::	two dimensional  tile .::	0
"me018"::	You're shifting the feature space.  Yeah.::	0
"mn052"::	So this is a two dimensional  tile .::	1
"mn052"::	And the L_D_A that we are f- applying is only in time, not in frequency -::	1
"mn052"::	high  cost frequency. So it's like - more like a filtering in time, rather than::	1
"me018"::	Ah. O_K.::	0
"mn052"::	doing a r-::	0
"me018"::	So what i- what about, um - i- u-::	0
"me018"::	what i- w- I mean, I don't know if this is a good idea or  not,  but what if you put - ran the  other  kind of L_D_A,::	1
"me018"::	uh, on your features right before they go into::	0
"mn052"::	Uh, it -::	0
"me018"::	the H_M_M?::	1
"mn052"::	m-::	0
"mn007"::	Mm-hmm. No, actually, I think - i- Well. What do we do with the A_N_N is -::	0
"mn007"::	is something like that except that it's not linear. But::	1
"me018"::	Yeah.::	0
"mn007"::	it's - it's like a nonlinear discriminant analysis. But.::	1
"me018"::	Right, it's the - It's - Right. The - So - Yeah, so it's sort of like - The  tandem  stuff is kind of like i-::	1
"mn007"::	Yeah. It's -::	0
"me018"::	nonlinear L_D_A.  I g-  Yeah.::	1
"mn007"::	Yeah.::	0
"me013"::	Yeah.::	0
"mn007"::	Uh.::	0
"me018"::	But I mean, w- but the  other  features that you have, um,::	1
"me018"::	th- the non- tandem  ones,::	1
"mn007"::	Mm-hmm.::	0
"mn007"::	Yeah, I know. That - that - Yeah. Well, in the proposal, they were::	1
"mn007"::	transformed u- using P_C_A, but -::	1
"me018"::	Uh-huh.::	0
"mn007"::	Yeah, it might be that L_D_A::	1
"me013"::	The a- the  argument  i- is kind of i- in - and it's not like we really  know,   but the  argument  anyway is that, um,::	0
"mn007"::	could be better.::	1
"me013"::	uh, we  always  have the prob- I mean, discriminative things are good. L_D_A, neural nets, they're good.::	0
"me018"::	Yeah.::	0
"me013"::	Uh, they're good because you - you - you learn to distinguish between these categories that you want to be good at distinguishing between.::	0
"me013"::	And P_C_A doesn't do that. It - P_A_C- P_C_A -::	0
"me013"::	low-order P_C_A throws away pieces that are::	0
"me013"::	uh, maybe not - not gonna be helpful just because they're  small,  basically.::	0
"me018"::	Right.::	0
"me013"::	But, uh, the problem is, training sets aren't perfect and testing sets are different.::	0
"me013"::	So you f- you - you face the  potential  problem with discriminative stuff, be it L_D_A or neural nets, that you are training::	0
"me013"::	to discriminate between categories in  one  space but what you're  really  gonna be g- getting is - is something  else.::	0
"me018"::	Uh-huh.::	0
"me013"::	And so, uh,  Stephane's  idea was,::	0
"me013"::	uh, let's feed, uh,  both  this discriminatively trained thing::	0
"me013"::	and something that's  not.::	0
"me013"::	So you have a  good  set of features that everybody's worked really hard to make,::	0
"me018"::	Yeah.::	0
"me013"::	and then, uh, you - you discriminately train it, but you  also::	0
"me013"::	take the path that - that  doesn't  have that, and putting those in  together.::	0
"me018"::	Uh-huh.::	0
"me013"::	And that - that seem- So it's kind of like a combination of the -::	0
"me013"::	uh, what, uh, Dan has been calling, you know, a feature - uh, you know, a feature combination versus posterior combination or something. It's -::	0
"me013"::	it's, you know, you  have  the posterior combination but then you get the features from  that  and use them as a feature combination with these - these other things.::	0
"me013"::	And that seemed, at least in the  last  one, as he was just saying, he -::	0
"me013"::	he - when he  only  did discriminative stuff,::	0
"me018"::	Yeah.::	0
"me013"::	i- it actually was - was - it didn't help at  all  in this particular case. There was enough of a difference, I guess, between the::	0
"me013"::	testing and training.::	0
"me013"::	But by having  them    both  there - The fact is  some  of the time,::	0
"me013"::	the discriminative stuff is gonna  help  you.::	0
"me018"::	Mm-hmm.::	0
"me013"::	And  some  of the time it's going to  hurt  you, and by combining two information sources if, you know - if - if -::	0
"me018"::	Right.::	0
"me018"::	So you wouldn't necessarily then want to do L_D_A on::	0
"me018"::	the non-tandem features because::	0
"me013"::	That i- i-::	0
"me018"::	now you're doing something to them that -::	0
"me013"::	I think that's counter to that idea. Now, again, it's - we're just trying these different things. We don't really know what's gonna work best. But::	0
"me018"::	Yeah, right.::	0
"me013"::	if that's the hypothesis, at least it would be counter to that hypothesis to do that.::	0
"me018"::	Right.::	0
"me013"::	Um, and in  principle  you would  think  that the neural net would do::	0
"me013"::	better::	0
"me013"::	at the  discriminant  part than L_D_A.::	0
"me018"::	Right.::	0
"me018"::	Yeah. Well - y-::	0
"me013"::	Though, maybe  not.::	0
"me018"::	Yeah.   Exactly.  I mean, we, uh - we were getting ready to do the tandem, uh, stuff for the Hub- five  system,::	0
"me018"::	and, um, Andreas and I  talked  about it, and::	0
"me018"::	the idea w- the  thought  was, "Well,::	0
"me018"::	uh, yeah, that i- you know - th- the neural net should be  better,  but we should at least have::	0
"me018"::	uh, a  number,  you know, to show that we did try the L_D_A::	0
"me018"::	in  place  of the neural net, so that we can::	0
"me013"::	Right.::	0
"me018"::	you know, show a clear  path.  You know, that you have it  without  it, then you have the L_D_A, then you have the neural net, and you can see,::	0
"me018"::	theoretically. So.::	0
"me018"::	I was just wondering - I - I -::	0
"me013"::	Well, I think that's a good idea.::	0
"me018"::	Yeah.::	0
"me013"::	Did - did you  do  that or - tha- that's a -::	0
"me018"::	Um. No. That's what - that's what we're gonna do  next  as soon as I finish this other thing. So.::	0
"me013"::	Yeah.  Yeah. No, well, that's a good idea.::	0
"me013"::	I - I -::	0
"me013"::	i- Yeah.::	0
"me018"::	We just want to  show.  I mean, it - everybody  believes  it, but you know, we just -::	0
"me013"::	Oh, no it's a g-::	0
"me013"::	No, no, but it might not - not even be  true.  I mean, it's - it's - it's - it's - it's a great idea. I mean,::	0
"me018"::	Yeah.::	0
"me013"::	one of the things that always disturbed me, uh, in the - the resurgence of neural nets that happened in the eighties was that, um,::	0
"me013"::	a lot of people - Because neural nets were pretty easy to - to use -::	0
"me018"::	Yeah.::	0
"me013"::	a lot of people were just using them for all sorts of things without,::	0
"me013"::	uh, looking at  all  into the linear, uh - uh,  versions  of them. And,::	0
"me018"::	Mm-hmm.::	0
"me018"::	Yeah.::	0
"me013"::	uh, people were doing recurrent nets but not looking at I_I_R filters, and - You know, I mean, uh, so I think, yeah, it's definitely a good idea to try it.::	0
"me018"::	Yeah, and everybody's putting that on their   systems  now, and so, I- that's what made me wonder about::	0
"me013"::	Well, they've been putting them in their systems off and on for ten years, but - but - but, uh,::	0
"me018"::	this, but.::	0
"me018"::	Yeah, what I mean is it's - it's like in the Hub-five evaluations, you know, and you read the system descriptions and::	0
"me013"::	And now they all have that.::	0
"me018"::	everybody's  got,  you know, L_D_A on their features. And so. Uh.::	0
"me013"::	I see.::	0
"me013"::	Yeah.::	0
"mn007"::	It's the transformation they're estimating on -::	0
"mn007"::	Well, they are trained on the same::	0
"mn007"::	data::	0
"mn007"::	as the final  H_M_M  are.::	0
"me018"::	Yeah, so it's  different.  Yeah, exactly. Cuz  they  don't have these, you know, mismatches that - that  you  guys have. So that's why I was wondering if maybe it's not even a good idea. I don't know.::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Mm-hmm.::	0
"me018"::	I - I don't know enough about it, but - Um.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	I mean,  part  of why - I - I think part of why you were getting into the K_L_T - Y- you were::	0
"me013"::	describing to me at one point that you wanted to::	0
"me013"::	see if,::	0
"me013"::	uh, you know, getting good orthogonal features was - and  combining  the - the different::	0
"me013"::	temporal::	0
"me013"::	ranges  - was the key thing that was happening or whether it was this discriminant thing, right? So you were just trying -::	0
"me013"::	I think you r- I mean, this is - it doesn't have the::	0
"me013"::	L_D_A aspect but th- as far as the::	0
"me013"::	orthogonalizing transformation, you were trying  that  at one point, right?::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	I think you were.::	0
"mn007"::	Yeah.::	0
"me013"::	Does  something.  It doesn't work as well.::	0
"me013"::	Yeah.::	0
"me013"::	Yeah.::	0
"mn052"::	So, yeah, I've been exploring a parallel V_A_D without neural network with, like,::	0
"mn052"::	less latency using S_N_R and energy,::	0
"mn052"::	um, after the cleaning up.::	0
"mn052"::	So what I'd been trying was, um,::	0
"mn052"::	uh -::	0
"mn052"::	After the b- after the noise compensation,::	0
"mn052"::	n- I was trying t- to f- find a f- feature based on the ratio of the energies, that is, cl- after clean and before clean.::	0
"mn052"::	So that if - if they are, like, pretty c- close to one, which means it's speech. And if it is n- if it is close to zero, which is -::	0
"mn052"::	So it's like a scale  @@  probability value.::	0
"mn052"::	So I was trying, uh, with full band and multiple bands,::	0
"mn052"::	m- ps- uh - separating them to different frequency bands and deriving separate decisions on each bands, and trying to combine them.::	0
"mn052"::	Uh,::	0
"mn052"::	the advantage being like it doesn't have the latency of the neural net if it - if it can g- And  it gave me like, uh, one point -::	0
"me013"::	Mm-hmm.::	0
"mn052"::	One - more than one percent  relative   improvement. So, from fifty-three point six it went to fifty f- four point eight. So it's, like,::	0
"mn052"::	only  slightly more than a percent improvement, just like -::	0
"me013"::	Mm-hmm.::	0
"mn052"::	Which means that it's - it's doing a slightly better job than the previous V_A_D,::	0
"me013"::	Mm-hmm.::	0
"mn052"::	uh, at a l- lower delay.::	0
"me013"::	Mm-hmm.::	0
"mn052"::	Um, so, um - so - u-::	0
"me013"::	But - i- d- I'm sorry, does it still have the median  filter stuff?::	0
"mn052"::	It  still  has the median filter. So -::	0
"me013"::	So it still has  most  of the delay, it just doesn't -::	0
"mn052"::	Yeah, so d- with the delay, that's gone is the  input,  which is the sixty millisecond.::	0
"mn052"::	The forty plus  twenty.::	0
"mn052"::	At the input of the neural net you have this, uh, f- nine frames of context plus the delta.::	0
"me013"::	Well, w- i-::	0
"mn007"::	Mm-hmm.::	0
"me013"::	Oh, plus the delta, right. O_K.::	0
"mn052"::	Yeah. So that delay, plus the L_D_A.::	0
"me013"::	Mm-hmm.::	0
"mn052"::	Uh, so the delay is only the forty millisecond of the noise cleaning, plus the hundred millisecond smoothing at the output.::	0
"me013"::	Mm-hmm. Mm-hmm.::	0
"mn052"::	Um.::	0
"mn052"::	So. Yeah. So the - the - di- the biggest -::	0
"mn052"::	The problem f- for me was to find a consistent threshold that works  well across the different databases, because I t-::	0
"mn052"::	I try to make it work on tr- SpeechDat-Car and it fails on T_I-digits, or if I try to make it work on that it's just the Italian or something, it doesn't work on the Finnish.::	0
"me013"::	Mm-hmm.::	0
"me013"::	Mm-hmm.::	0
"mn052"::	So, um.::	0
"mn052"::	So there are - there was, like, some problem in balancing the deletions and insertions when I try different thresholds. So -::	0
"me013"::	Mm-hmm.::	0
"mn052"::	The -::	0
"mn052"::	I'm still trying to make it::	0
"mn052"::	better by using some other features from the -::	0
"mn052"::	after the p- clean up - maybe, some,::	0
"mn052"::	uh, correlation - auto-correlation or some s- additional features  of  - to mainly::	0
"mn052"::	the improvement of the  VAD .::	0
"mn052"::	I've been trying.::	0
"me013"::	Now this - this - this, uh,::	0
"me013"::	"before and  after  clean", it sounds like you think that's a good  feature.::	0
"me013"::	That - that, it - you th- think that the, uh - the -::	0
"me013"::	i- it appears to be a good feature, right?::	0
"mn052"::	Mm-hmm. Yeah.::	0
"me013"::	What about using it in the  neural  net?::	0
"mn007"::	Yeah, eventually we could - could just::	0
"mn052"::	Yeah, so - Yeah, so that's the - Yeah. So we've been thinking about putting it into the neural net also.::	0
"me013"::	Yeah.::	0
"mn052"::	Because they did - that itself -::	0
"mn007"::	Then you don't have to worry about the thresholds and -::	0
"mn052"::	There's a threshold and - Yeah. Yeah. So that - that's, uh -::	0
"me013"::	Yeah.::	0
"mn007"::	but just -::	0
"me013"::	Yeah. So if we - if we can  live  with the latency or cut the latencies  elsewhere,  then - then that would be a,::	0
"mn052"::	Yeah. Yeah.::	0
"me013"::	uh,::	0
"me013"::	good thing. Um, anybody - has anybody - you guys or - or  Naren , uh, somebody, tried the, uh,::	0
"me013"::	um,::	0
"me013"::	second th- second stream thing?::	0
"me013"::	Uh.::	0
"mn052"::	Oh, I just - I just h- put the second stream in place and, uh::	0
"mn052"::	ran one experiment, but just like - just to know that everything is fine.::	0
"me013"::	Uh-huh.::	0
"mn052"::	So it was like, uh, forty-five cepstrum plus twenty-three mel -  log  mel.::	0
"me013"::	Yeah.::	0
"mn052"::	And - and , just, like, it gave me the baseline performance of the Aurora, which is like::	0
"mn052"::	zero improvement.::	0
"me013"::	Yeah.::	0
"me013"::	Yeah.::	0
"mn052"::	So I just tried it on Italian just to know that everything is -  But I -  I  didn't export  anything  out of it because it was, like, a weird feature set.::	0
"me013"::	Yeah.::	0
"mn052"::	So.::	0
"me013"::	Yeah. Well, what I think, you know, would be  more  what you'd want to do is - is - is, uh, put it into another  neural  net.::	0
"mn052"::	Yeah, yeah, yeah, yeah.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	Right? And then -::	0
"me013"::	But, yeah, we're - we're not quite there yet. So we have to  figure out the neural nets, I guess.::	0
"mn007"::	Yeah.::	0
"mn052"::	The uh,  other  thing I was wondering was, um,::	1
"mn052"::	if the neural net, um, has any - because of the different noise con- unseen noise conditions for the::	0
"mn052"::	neural net, where, like, you train it on those four noise conditions,::	1
"mn007"::	Mm-hmm.::	0
"mn052"::	while you are feeding it with, like,::	0
"mn052"::	a- additional - some four plus some - f- few more conditions which it hasn't seen, actually,::	1
"mn052"::	from the - f- f- while testing. Um -::	0
"mn007"::	Yeah, yeah. Right.::	0
"mn052"::	instead of just h- having c-::	1
"mn052"::	uh, those cleaned up t- cepstrum, sh- should we feed some additional information, like -::	0
"mn052"::	The - the - We  have  the V_A_D  flag.  I mean, should we f- feed the V_A_D flag, also, at the input so that it - it has some additional discriminating information at the input?::	1
"mn007"::	Hmm- hmm!  Um -::	0
"me013"::	Wh- uh, the - the V_A_D what?::	0
"mn052"::	We have the V_A_D information also available at the  back-end.::	1
"me013"::	Uh-huh.::	0
"mn052"::	So if it is something the neural net is not able to discriminate the classes -::	1
"me013"::	Yeah.::	0
"mn052"::	I mean -::	0
"mn052"::	Because most of it is sil-::	0
"mn052"::	I mean, we have dropped some silence f-::	0
"mn052"::	We have dropped so- silence frames?   No,  we  haven't  dropped silence frames  still.::	0
"me013"::	Mm-hmm.::	0
"mn007"::	Uh, still  not.  Yeah.::	0
"mn052"::	Yeah. So - the b- b- biggest classification would be the speech and silence.::	0
"mn007"::	Th-::	0
"mn052"::	So, by having an additional, uh, feature which says "this is speech and this is  nonspeech ", I mean, it certainly helps in some unseen noise conditions for the  neural  net.::	1
"me018"::	What -::	0
"me018"::	Do y- do you have that feature available for the  test  data?::	0
"mn052"::	Well, I mean, we have - we are transferring the V_A_D to the  back-end  -  feature  to the  back-end.  Because we are dropping it at the  back-end  after everything - all the features are computed. So -::	0
"me018"::	Oh, oh,  I  see.  I  see.::	0
"mn052"::	so the neural - so that is coming from a separate neural net or  some  V_A_D.::	0
"me018"::	O_K. O_K.::	0
"mn052"::	Which is - which is certainly::	0
"mn052"::	giving a::	0
"me018"::	So you're saying, feed that,  also,  into::	1
"mn052"::	@@  to -  Yeah.  So it- it's an - additional discriminating information.::	1
"me018"::	the neural net. Yeah.  Yeah.::	1
"me018"::	Right.::	0
"me013"::	You could feed it into the neural net. The  other  thing  you could do::	1
"mn052"::	So that -::	0
"me013"::	is just, um, p-::	0
"me013"::	modify the, uh,  output  probabilities of the - of the, uh,::	0
"me013"::	uh,::	0
"me013"::	um, neural net,  tandem  neural net,  based on the fact that you have a  silence  probability.::	1
"mn052"::	Mm-hmm.::	0
"me013"::	Right?::	0
"mn007"::	Mm-hmm.::	0
"me013"::	So you have an independent estimator of what the silence probability is,::	0
"me013"::	and you could  multiply  the two things, and renormalize.::	0
"me013"::	Uh, I mean, you'd have to do the::	0
"mn007"::	Yeah.::	0
"me013"::	nonlinearity part and deal with  that.  Uh, I mean, go backwards from what the nonlinearity would, you know - would be. But - but, uh -::	0
"mn052"::	Through  - t- to the soft  max .::	0
"mn007"::	Yeah, so - maybe, yeah, when -::	0
"me018"::	But in principle wouldn't it be  better  to feed it in? And let the  net  do that?::	0
"me013"::	Well, u- Not  sure.::	0
"me013"::	I mean, let's put it  this  way. I mean, y- you - you have this complicated system with thousands and thousand parameters::	0
"me018"::	Hmm.::	0
"me018"::	Yeah.::	0
"me013"::	and you can tell it, uh, " Learn  this  thing. "::	0
"me013"::	Or you can say, "It's  silence!  Go  away! "::	0
"me013"::	I mean,  I mean, i- Doesn't - ? I think - I think the  second  one sounds a lot more  direct.   Uh.::	0
"me018"::	What -::	0
"me018"::	what if you -  Right.::	0
"me018"::	So, what if you then, uh - since you  know  this, what if you only::	0
"me018"::	use the  neural  net on the  speech  portions?::	0
"me013"::	Well, uh,::	0
"mn007"::	That's what -::	0
"me018"::	Well, I guess that's the  same.  Uh, that's  similar.::	0
"me013"::	Yeah, I mean, y- you'd have to actually  run  it  continuously,  but it's -  @@  -::	0
"me018"::	But I mean - I mean,  train  the net only on -::	0
"me013"::	Well, no, you want to train on - on the nonspeech  also,  because that's part of what you're  learning  in it,::	0
"me013"::	to - to - to generate, that it's - it has to distinguish  between.::	0
"mn052"::	Speech.::	0
"me018"::	But I mean, if you're gonna - if you're going to multiply the output of the net by this other  decision,::	0
"me018"::	uh,::	0
"me018"::	would - then you don't  care  about whether the net makes that distinction, right?::	0
"me013"::	Well, yeah. But this  other  thing isn't  perfect.::	0
"me018"::	Ah.::	0
"me013"::	So that you bring in  some  information from the net  itself.::	0
"me018"::	Right, O_K. That's a good point.::	0
"me013"::	Yeah. Now the only thing that - that bothers me about all this is that I - I - I -::	1
"me013"::	The - the fact -::	1
"me013"::	i- i- It's  sort  of bothersome that you're getting more  deletions.::	1
"mn007"::	Yeah.::	0
"mn007"::	But -::	1
"mn007"::	So I might maybe look at,::	1
"mn007"::	is it due to the fact that::	1
"mn007"::	um, the probability of the silence at the output of the network, is,::	1
"mn007"::	uh,::	0
"me013"::	Is too  high.::	0
"mn007"::	too - too high or -::	1
"mn007"::	If it's the case, then multiplying it again by -::	0
"me013"::	Yeah. So maybe - So -::	0
"mn052"::	It may not be - it -::	0
"mn007"::	i- by something? Mm-hmm.::	0
"mn052"::	Yeah, it - it may be too - it's too high in a sense, like, everything is more like a, um,::	0
"me013"::	Yeah.::	0
"mn052"::	flat probability.::	0
"me013"::	Yeah.::	0
"mn052"::	So, like, it's not  really  doing any distinction between speech and nonspeech - or, I mean, different -  among  classes.::	0
"mn007"::	Oh-eee-hhh.::	0
"mn007"::	Uh, yeah.::	0
"me013"::	Yeah.::	0
"mn007"::	Mm-hmm.::	0
"me018"::	Be interesting to look at the - Yeah, for the -::	0
"me018"::	I wonder if you could  do  this.::	0
"me018"::	But if you look at the, um, highly mism- high mismat- the output of the net on the  high  mismatch case and just look at, you know, the  distribution::	0
"me018"::	versus the - the  other  ones, do you - do you see more  peaks  or something?::	0
"mn007"::	Yeah.::	0
"mn007"::	Yeah, like the entropy of the - the output, or -::	0
"me018"::	Yeah.::	0
"me013"::	Yeah, for instance.::	0
"mn007"::	It - it seems that the V_A_D network doesn't - Well,::	0
"me013"::	But I - bu-::	0
"mn007"::	it doesn't drop,::	0
"mn007"::	uh, too many frames because the dele- the number of deletion is reasonable.::	0
"mn007"::	But it's just when we add the tandem,::	0
"mn007"::	the final M_L_P, and then -::	0
"me013"::	Yeah. Now the  only  problem is you  don't  want to ta- I guess  wait  for the  output  of the V_A_D::	0
"mn007"::	u-::	0
"me013"::	before you can put something  into  the other  system,  cuz that'll shoot up the latency a  lot,  right? Am I  missing  something here?::	0
"mn052"::	Mm-hmm.::	0
"mn007"::	But -::	0
"mn007"::	Yeah.::	0
"mn007"::	Right.::	0
"me013"::	Yeah. So that's maybe a  problem  with what I was just saying. But -::	0
"me013"::	but - I- I guess -::	0
"me018"::	But if you were gonna  put  it in as a  feature  it means you already  have  it by the time you get to the  tandem  net, right?::	0
"mn052"::	Um, well. We - w- we don't have it, actually, because it's - it has a high  rate energy  - the V_A_D has a -::	0
"me013"::	No.::	0
"me018"::	Ah.::	0
"me013"::	Yeah.::	0
"me018"::	O_K.::	0
"me013"::	It's  kind  of done in - I mean,  some  of the things are,::	0
"me013"::	not in parallel,  but::	0
"me013"::	certainly,::	0
"me013"::	it would be in parallel with the - with a  tandem  net.::	0
"me018"::	Right.::	0
"me013"::	In time.::	0
"me013"::	So maybe, if that doesn't work, um -::	0
"me013"::	But it would be interesting to see if that was the problem, anyway.::	0
"me013"::	And - and - and then I guess another alternative  would  be to take the feature that you're feeding into the V_A_D,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	and feeding it into the other one as well.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	And then maybe it would just learn -  learn  it better.::	0
"me013"::	Um -::	1
"me013"::	But that's - Yeah, that's an interesting thing to try to  see,  if what's going on::	0
"me013"::	is that in the highly mismatched condition,::	0
"me013"::	it's, um, causing deletions by having this silence probability up - up too high,::	0
"mn007"::	Mm-hmm.::	0
"me013"::	at some point where the V_A_D is saying it's actually speech.::	0
"mn007"::	Yeah. So, m-::	0
"me013"::	Which is probably  true.::	0
"me013"::	Cuz - Well, the V_A_- if the V_A_D said - since the V_A_D is - is - is  right  a lot,  uh -::	0
"mn007"::	Yeah.::	0
"me013"::	Hmm. Anyway.::	0
"me013"::	Might  be.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	Yeah. Well, we just started working with it. But these are - these are some good ideas I think.::	0
"mn007"::	Mm-hmm.::	0
"mn007"::	Yeah, and the other thing - Well, there are other issues maybe for the tandem, like,::	0
"mn007"::	uh, well, do we want to, w- uh n-::	0
"mn007"::	Do we want to work on the targets? Or,::	0
"mn007"::	like, instead of using phonemes, using more context dependent::	0
"mn007"::	units?::	0
"me018"::	For the tandem net you mean? Hmm.::	0
"mn007"::	Well, I'm -::	0
"mn007"::	Yeah. I'm thinking, also, a w- about::	0
"mn007"::	Dan's work::	0
"mn007"::	where he -::	0
"mn007"::	he trained  a network, not on phoneme targets but on the H_M_M state targets.::	0
"mn007"::	And -::	0
"mn007"::	it was giving s- slightly better::	0
"mn007"::	results.::	0
"me013"::	Problem  is, if you are::	0
"me013"::	going to run this on different::	0
"me013"::	m-::	0
"mn007"::	Yeah.::	0
"me013"::	test sets, including large vocabulary,::	0
"mn007"::	Yeah.::	0
"me013"::	um,::	0
"mn007"::	Uh -::	0
"mn007"::	Mmm. I was just thinking maybe about,::	0
"me013"::	I think -::	1
"mn007"::	like, generalized diphones, and -::	0
"mn007"::	come up with a -::	0
"mn007"::	a reasonable,::	0
"mn007"::	not too large, set of context dependent units, and -::	0
"mn007"::	and -::	0
"mn007"::	Yeah.::	0
"mn007"::	And then anyway we would have to reduce this with the K_L_T. So. But -  I don't know.::	0
"me013"::	Yeah.::	0
"me013"::	Yeah.  Well, maybe.::	0
"mn007"::	Mm-hmm.::	0
"me013"::	But I d- I d- it - it - i-::	0
"me013"::	it's all worth looking at, but it sounds to me like, uh, looking at the relationship between this and the - speech noise stuff is - is -::	0
"mn007"::	Mm-hmm.::	0
"me013"::	is probably a key thing.::	0
"me013"::	That and the correlation  between  stuff.::	0
"me018"::	So if, uh -::	0
"me018"::	if the, uh, high mismatch case had been more like the,::	0
"me018"::	uh,::	0
"me018"::	the other two cases  in terms of giving you just a better performance,::	0
"mn007"::	Mm-hmm.::	0
"me018"::	how would this number have changed?::	0
"mn007"::	Oh, it would be -::	0
"mn007"::	Yeah.::	0
"mn007"::	Around five percent  better,  I guess. If -::	0
"me018"::	y- Like sixty?::	0
"mn007"::	if - i-::	0
"me013"::	Well, we don't know what's it's gonna be the T_I-digits yet. He hasn't got the results back yet.::	0
"mn007"::	Yeah.::	0
"mn007"::	If you extrapolate the SpeechDat-Car well-matched and medium-mismatch,::	0
"me018"::	Uh-huh.::	0
"me018"::	Yeah.::	0
"mn007"::	it's around, yeah, maybe five.::	0
"me018"::	So this would be::	0
"me018"::	sixty-two?::	0
"me013"::	Sixty- two.::	0
"mn007"::	Sixty-two, yeah.::	0
"me013"::	Yeah.::	0
"mn052"::	Somewhere around sixty, must be.::	0
"me018"::	Which is -::	0
"mn052"::	Right? Yeah.::	0
"mn007"::	Well, it's around five  percent,  because it's - s- Right? If everything is five  percent.::	0
"mn052"::	Yeah. Yeah.::	0
"mn007"::	Mm-hmm.::	0
"me018"::	All the  other  ones were five percent, the -::	0
"mn007"::	I d- I d- I just have the SpeechDat-Car right now, so -::	0
"me013"::	Yeah.::	0
"me018"::	Yeah.::	0
"mn007"::	It's running - it shou- we should have the results today during the afternoon, but -::	0
"me018"::	Hmm.::	0
"mn007"::	Well.::	0
"me013"::	Hmm.::	0
"me013"::	Well -::	0
"me013"::	Um -::	0
"me013"::	So I won't be here::	1
"me013"::	for -::	1
"me018"::	When -::	0
"me018"::	When do you leave?::	0
"me013"::	Uh, I'm leaving next Wednesday.::	1
"me013"::	May or may not be in in the morning. I leave in the afternoon.::	0
"me013"::	Um, so I -::	0
"me018"::	But you're - are you - you're not gonna be around this afternoon?::	0
"me013"::	Yeah.::	0
"me013"::	Oh, well. I'm talking about  next  week. I'm leaving - leaving  next  Wednesday.::	1
"me018"::	Oh.::	0
"me013"::	This afternoon - uh - Oh, right, for the Meeting meeting? Yeah, that's just cuz of something on campus.::	0
"me018"::	Uh-huh.::	0
"me018"::	Ah, O_K, O_K.::	0
"me013"::	Yeah.::	0
"me013"::	But, um,::	0
"me013"::	yeah, so next week I won't,::	1
"me013"::	and the week after I won't, cuz I'll be in Finland.::	1
"me013"::	And the week after that I won't.::	0
"me013"::	By that time  you'll  be -::	1
"me013"::	Uh, you'll  both  be gone  from  here.::	1
"me013"::	So there'll be no - definitely no meeting on - on September sixth.::	0
"me013"::	Uh, and -::	0
"me018"::	What's September sixth?::	0
"me013"::	Uh, that's during  Eurospeech.::	0
"me018"::	Oh, oh, right. O_K.::	0
"me013"::	So, uh, Sunil will be in Oregon. Uh, Stephane and I will be in Denmark.::	0
"me013"::	Uh -::	0
"me013"::	Right?::	0
"me013"::	So it'll be a few weeks, really, before we have a meeting of the same::	1
"me013"::	cast of characters.::	1
"me013"::	Um, but, uh -::	0
"me013"::	I guess,::	0
"me013"::	just -::	0
"me013"::	I mean, you guys should probably meet. And maybe Barry - Barry will be around. And -::	0
"me013"::	and then uh,::	1
"me013"::	uh, we'll start up again with::	0
"me013"::	Dave and - Dave and Barry and Stephane::	0
"me013"::	and us on the, uh,::	0
"me013"::	twentieth.::	1
"me013"::	No.::	0
"me013"::	Thirteenth?::	0
"me013"::	About a month?::	0
"me018"::	So, uh, you're gonna be gone for the next::	0
"me018"::	three  weeks or something?::	0
"me013"::	I'm gone for two and a half weeks starting - starting next Wed- late next Wednesday.::	0
"me018"::	So that's - you won't be at the next three of these meetings.::	0
"me018"::	Is that right?::	0
"me013"::	Uh, I won't -::	0
"me013"::	it's probably  four  because of -::	0
"me013"::	is it  three?  Let's see,::	0
"me013"::	twenty-third, thirtieth,::	0
"me013"::	sixth. That's right, next three.::	0
"me013"::	And the - the  third  one::	0
"me013"::	won't - probably won't  be  a meeting, cuz - cuz, uh, Su- Sunil, Stephane, and I will all not be here.::	0
"me018"::	Oh, right. Right.::	0
"me013"::	Um -::	0
"me013"::	Mmm.  So it's just, uh, the next  two::	0
"me013"::	where there will be - there, you know, may as well be meetings, but I just won't be at them.::	0
"me018"::	O_K.::	0
"me013"::	And then starting up on the  thirteenth,::	0
"me013"::	uh, we'll have meetings again but we'll have to do without  Sunil  here somehow.  So.::	0
"me018"::	When do you go back?::	0
"mn052"::	Thirty-first, August.::	0
"me013"::	Yeah.::	0
"me013"::	Yeah.::	0
"me013"::	So.::	0
"me013"::	Cool .::	0
"me018"::	When is the evaluation? November, or something?::	0
"me013"::	Yeah, it was supposed to be November fifteenth. Has anybody heard anything different?::	0
"mn007"::	I don't know. The meeting in - is the five and six of December.::	0
"mn052"::	p- s- It's like - Yeah, it's tentatively  all full . Yeah.::	0
"mn007"::	So -::	0
"mn007"::	Mm-hmm.::	0
"mn052"::	Uh, that's a proposed date, I guess.::	0
"mn007"::	Yeah, um -::	0
"mn007"::	so the evaluation should be  on::	0
"mn007"::	a week before or -::	0
"me018"::	Yeah.::	0
"me013"::	Yep.::	0
"me013"::	But, no, this is good progress.::	0
"me013"::	So.::	0
"me013"::	Uh -::	0
"me013"::	O_K.::	0
"me013"::	Guess we're done.::	0
"me018"::	Should we do digits?::	0
"me013"::	Digits? Yep.::	0
"me018"::	O_K.::	0
"me013"::	It's a wrap.::	0
